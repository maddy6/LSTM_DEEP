{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173b4909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pixel\\AppData\\Local\\Temp\\ipykernel_12792\\2451059119.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anomaly_df[['Age', 'Income']] = discretizer.fit_transform(anomaly_df[['Age', 'Income']])\n",
      "C:\\Users\\pixel\\AppData\\Local\\Temp\\ipykernel_12792\\2451059119.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anomaly_df['Age'] = anomaly_df['Age'] <= threshold\n",
      "C:\\Users\\pixel\\AppData\\Local\\Temp\\ipykernel_12792\\2451059119.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anomaly_df['Income'] = anomaly_df['Income'] <= threshold\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Association Rules:\n",
      "                   antecedents    consequents  antecedent support  \\\n",
      "0                     (Income)          (Age)            0.833333   \n",
      "1                        (Age)       (Income)            0.833333   \n",
      "2              (Education_Low)          (Age)            0.333333   \n",
      "4              (Education_Low)       (Income)            0.333333   \n",
      "6      (Education_Low, Income)          (Age)            0.333333   \n",
      "8         (Education_Low, Age)       (Income)            0.333333   \n",
      "10             (Education_Low)  (Age, Income)            0.333333   \n",
      "12  (Education_Medium, Income)          (Age)            0.333333   \n",
      "13     (Education_Medium, Age)       (Income)            0.333333   \n",
      "16       (Gender_Male, Income)          (Age)            0.333333   \n",
      "17          (Gender_Male, Age)       (Income)            0.333333   \n",
      "\n",
      "    consequent support   support  confidence  lift  leverage  conviction  \\\n",
      "0             0.833333  0.833333         1.0   1.2  0.138889         inf   \n",
      "1             0.833333  0.833333         1.0   1.2  0.138889         inf   \n",
      "2             0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "4             0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "6             0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "8             0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "10            0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "12            0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "13            0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "16            0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "17            0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "\n",
      "    zhangs_metric  \n",
      "0            1.00  \n",
      "1            1.00  \n",
      "2            0.25  \n",
      "4            0.25  \n",
      "6            0.25  \n",
      "8            0.25  \n",
      "10           0.25  \n",
      "12           0.25  \n",
      "13           0.25  \n",
      "16           0.25  \n",
      "17           0.25  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract rows where Anomaly is True\n",
    "anomaly_df = df[df['Anomaly'] == True]\n",
    "\n",
    "# Discretize numerical variables (Age, Income) into bins\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "anomaly_df[['Age', 'Income']] = discretizer.fit_transform(anomaly_df[['Age', 'Income']])\n",
    "\n",
    "# Manually convert discretized values to binary using a threshold\n",
    "threshold = 2  # Adjust this threshold as needed\n",
    "anomaly_df['Age'] = anomaly_df['Age'] <= threshold\n",
    "anomaly_df['Income'] = anomaly_df['Income'] <= threshold\n",
    "\n",
    "# Encode categorical variables as binary\n",
    "anomaly_df_encoded = pd.get_dummies(anomaly_df.drop(columns=['Anomaly']), drop_first=True)\n",
    "\n",
    "# Perform Apriori algorithm for frequent itemset generation\n",
    "frequent_itemsets = apriori(anomaly_df_encoded, min_support=0.3, use_colnames=True)\n",
    "\n",
    "# Generate association rules from frequent itemsets\n",
    "association_rules_df = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Filter the association rules based on desired metrics (e.g., lift, confidence)\n",
    "filtered_rules = association_rules_df[(association_rules_df['lift'] >= 1.0) & (association_rules_df['confidence'] >= 0.7)]\n",
    "\n",
    "# Print the filtered association rules\n",
    "print(\"Filtered Association Rules:\")\n",
    "print(filtered_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90acd2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human-Readable Association Rules:\n",
      "If Income, then Age (Support: 0.8333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Age, then Income (Support: 0.8333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Low, then Age (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Low, then Income (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Low, Income, then Age (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Low, Age, then Income (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Low, then Age, Income (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Medium, Income, then Age (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Medium, Age, then Income (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Gender_Male, Income, then Age (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Gender_Male, Age, then Income (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n"
     ]
    }
   ],
   "source": [
    "# Convert association rules to a human-readable format\n",
    "def convert_rules_to_readable(rules_df):\n",
    "    readable_rules = []\n",
    "    for _, row in rules_df.iterrows():\n",
    "        antecedents = row['antecedents']\n",
    "        consequents = row['consequents']\n",
    "        support = row['support']\n",
    "        confidence = row['confidence']\n",
    "        lift = row['lift']\n",
    "        \n",
    "        antecedent_str = ', '.join([str(antecedent) for antecedent in antecedents])\n",
    "        consequent_str = ', '.join([str(consequent) for consequent in consequents])\n",
    "        \n",
    "        rule_str = f\"If {antecedent_str}, then {consequent_str}\"\n",
    "        metrics_str = f\"Support: {support:.4f}, Confidence: {confidence:.4f}, Lift: {lift:.4f}\"\n",
    "        \n",
    "        readable_rule = f\"{rule_str} ({metrics_str})\"\n",
    "        readable_rules.append(readable_rule)\n",
    "    \n",
    "    return readable_rules\n",
    "\n",
    "# Convert the filtered association rules to human-readable format\n",
    "human_readable_rules = convert_rules_to_readable(filtered_rules)\n",
    "\n",
    "# Print the human-readable rules\n",
    "print(\"Human-Readable Association Rules:\")\n",
    "for rule in human_readable_rules:\n",
    "    print(rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734f3188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c985b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Association Rules:\n",
      "                   antecedents    consequents  antecedent support  \\\n",
      "0                     (Income)          (Age)            0.833333   \n",
      "1                        (Age)       (Income)            0.833333   \n",
      "2              (Education_Low)          (Age)            0.333333   \n",
      "4              (Education_Low)       (Income)            0.333333   \n",
      "6      (Education_Low, Income)          (Age)            0.333333   \n",
      "8         (Education_Low, Age)       (Income)            0.333333   \n",
      "10             (Education_Low)  (Age, Income)            0.333333   \n",
      "12  (Education_Medium, Income)          (Age)            0.333333   \n",
      "13     (Education_Medium, Age)       (Income)            0.333333   \n",
      "16       (Gender_Male, Income)          (Age)            0.333333   \n",
      "17          (Gender_Male, Age)       (Income)            0.333333   \n",
      "\n",
      "    consequent support   support  confidence  lift  leverage  conviction  \\\n",
      "0             0.833333  0.833333         1.0   1.2  0.138889         inf   \n",
      "1             0.833333  0.833333         1.0   1.2  0.138889         inf   \n",
      "2             0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "4             0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "6             0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "8             0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "10            0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "12            0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "13            0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "16            0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "17            0.833333  0.333333         1.0   1.2  0.055556         inf   \n",
      "\n",
      "    zhangs_metric  \n",
      "0            1.00  \n",
      "1            1.00  \n",
      "2            0.25  \n",
      "4            0.25  \n",
      "6            0.25  \n",
      "8            0.25  \n",
      "10           0.25  \n",
      "12           0.25  \n",
      "13           0.25  \n",
      "16           0.25  \n",
      "17           0.25  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pixel\\AppData\\Local\\Temp\\ipykernel_12792\\2451059119.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anomaly_df[['Age', 'Income']] = discretizer.fit_transform(anomaly_df[['Age', 'Income']])\n",
      "C:\\Users\\pixel\\AppData\\Local\\Temp\\ipykernel_12792\\2451059119.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anomaly_df['Age'] = anomaly_df['Age'] <= threshold\n",
      "C:\\Users\\pixel\\AppData\\Local\\Temp\\ipykernel_12792\\2451059119.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anomaly_df['Income'] = anomaly_df['Income'] <= threshold\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract rows where Anomaly is True\n",
    "anomaly_df = df[df['Anomaly'] == True]\n",
    "\n",
    "# Discretize numerical variables (Age, Income) into bins\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "anomaly_df[['Age', 'Income']] = discretizer.fit_transform(anomaly_df[['Age', 'Income']])\n",
    "\n",
    "# Manually convert discretized values to binary using a threshold\n",
    "threshold = 2  # Adjust this threshold as needed\n",
    "anomaly_df['Age'] = anomaly_df['Age'] <= threshold\n",
    "anomaly_df['Income'] = anomaly_df['Income'] <= threshold\n",
    "\n",
    "# Encode categorical variables as binary\n",
    "anomaly_df_encoded = pd.get_dummies(anomaly_df.drop(columns=['Anomaly']), drop_first=True)\n",
    "\n",
    "# Perform Apriori algorithm for frequent itemset generation\n",
    "frequent_itemsets = apriori(anomaly_df_encoded, min_support=0.3, use_colnames=True)\n",
    "\n",
    "# Generate association rules from frequent itemsets\n",
    "association_rules_df = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Filter the association rules based on desired metrics (e.g., lift, confidence)\n",
    "filtered_rules = association_rules_df[(association_rules_df['lift'] >= 1.0) & (association_rules_df['confidence'] >= 0.7)]\n",
    "\n",
    "# Print the filtered association rules\n",
    "print(\"Filtered Association Rules:\")\n",
    "print(filtered_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd549253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]\n"
     ]
    }
   ],
   "source": [
    "print(df['Anomaly'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ea8e530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human-Readable Association Rules:\n",
      "If Income, then Age (Support: 0.8333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Age, then Income (Support: 0.8333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Low, then Age (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Low, then Income (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Low, Income, then Age (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Low, Age, then Income (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Low, then Age, Income (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Medium, Income, then Age (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Education_Medium, Age, then Income (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Gender_Male, Income, then Age (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n",
      "If Gender_Male, Age, then Income (Support: 0.3333, Confidence: 1.0000, Lift: 1.2000)\n"
     ]
    }
   ],
   "source": [
    "# Convert association rules to a human-readable format\n",
    "def convert_rules_to_readable(rules_df):\n",
    "    readable_rules = []\n",
    "    for _, row in rules_df.iterrows():\n",
    "        antecedents = row['antecedents']\n",
    "        consequents = row['consequents']\n",
    "        support = row['support']\n",
    "        confidence = row['confidence']\n",
    "        lift = row['lift']\n",
    "        \n",
    "        antecedent_str = ', '.join([str(antecedent) for antecedent in antecedents])\n",
    "        consequent_str = ', '.join([str(consequent) for consequent in consequents])\n",
    "        \n",
    "        rule_str = f\"If {antecedent_str}, then {consequent_str}\"\n",
    "        metrics_str = f\"Support: {support:.4f}, Confidence: {confidence:.4f}, Lift: {lift:.4f}\"\n",
    "        \n",
    "        readable_rule = f\"{rule_str} ({metrics_str})\"\n",
    "        readable_rules.append(readable_rule)\n",
    "    \n",
    "    return readable_rules\n",
    "\n",
    "# Convert the filtered association rules to human-readable format\n",
    "human_readable_rules = convert_rules_to_readable(filtered_rules)\n",
    "\n",
    "# Print the human-readable rules\n",
    "print(\"Human-Readable Association Rules:\")\n",
    "for rule in human_readable_rules:\n",
    "    print(rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca5a0458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Medium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Create and fit the decision tree classifier\u001b[39;00m\n\u001b[0;32m     12\u001b[0m clf \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier()\n\u001b[1;32m---> 13\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Extract rules where Anomaly is True\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_rules\u001b[39m(tree, feature_names):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:186\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    184\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    185\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 186\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    190\u001b[0m     X\u001b[38;5;241m.\u001b[39msort_indices()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:560\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_X_params:\n\u001b[0;32m    559\u001b[0m     check_X_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params}\n\u001b[1;32m--> 560\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params)\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[0;32m    562\u001b[0m     check_y_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params}\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Medium'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate your dataset into features and target variable\n",
    "X = df[['Age', 'Income', 'Education', 'Gender']]\n",
    "y = df['Anomaly']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Extract rules where Anomaly is True\n",
    "def extract_rules(tree, feature_names):\n",
    "    rules = []\n",
    "    for node in tree.children_left:\n",
    "        if node != -1:\n",
    "            feature = feature_names[tree.feature[node]]\n",
    "            threshold = tree.threshold[node]\n",
    "            left_rule = f\"{feature} <= {threshold}\"\n",
    "            right_rule = f\"{feature} > {threshold}\"\n",
    "            rules.append(left_rule)\n",
    "            rules.append(right_rule)\n",
    "            rules.extend(extract_rules(tree.children_left[node], feature_names))\n",
    "            rules.extend(extract_rules(tree.children_right[node], feature_names))\n",
    "    return rules\n",
    "\n",
    "rules = extract_rules(clf.tree_, X.columns.tolist())\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820e06b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a9fc743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('30',): (('60000', 'Female', 'Low'), 1.0), ('30', 'Female'): (('60000', 'Low'), 1.0), ('30', 'Low'): (('60000', 'Female'), 1.0), ('Female', 'Low'): (('30', '60000'), 1.0), ('60000',): (('30', 'Female', 'Low'), 1.0), ('30', '60000'): (('Female', 'Low'), 1.0), ('60000', 'Low'): (('30', 'Female'), 1.0), ('60000', 'Female'): (('30', 'Low'), 1.0), ('30', '60000', 'Female'): (('Low',), 1.0), ('30', '60000', 'Low'): (('Female',), 1.0), ('30', 'Female', 'Low'): (('60000',), 1.0), ('60000', 'Female', 'Low'): (('30',), 1.0), ('35',): (('70000', 'Female', 'Medium'), 1.0), ('35', 'Female'): (('70000', 'Medium'), 1.0), ('35', 'Medium'): (('70000', 'Female'), 1.0), ('70000',): (('35', 'Female', 'Medium'), 1.0), ('35', '70000'): (('Female', 'Medium'), 1.0), ('70000', 'Female'): (('35', 'Medium'), 1.0), ('70000', 'Medium'): (('35', 'Female'), 1.0), ('35', '70000', 'Female'): (('Medium',), 1.0), ('35', '70000', 'Medium'): (('Female',), 1.0), ('35', 'Female', 'Medium'): (('70000',), 1.0), ('70000', 'Female', 'Medium'): (('35',), 1.0), ('28',): (('55000', 'High', 'Male'), 1.0), ('55000',): (('28', 'High', 'Male'), 1.0), ('28', '55000'): (('High', 'Male'), 1.0), ('28', 'Male'): (('55000', 'High'), 1.0), ('55000', 'Male'): (('28', 'High'), 1.0), ('High',): (('28', '55000', 'Male'), 1.0), ('28', 'High'): (('55000', 'Male'), 1.0), ('55000', 'High'): (('28', 'Male'), 1.0), ('High', 'Male'): (('28', '55000'), 1.0), ('28', '55000', 'High'): (('Male',), 1.0), ('28', '55000', 'Male'): (('High',), 1.0), ('28', 'High', 'Male'): (('55000',), 1.0), ('55000', 'High', 'Male'): (('28',), 1.0), ('45',): (('90000', 'Male', 'Medium'), 1.0), ('45', 'Male'): (('90000', 'Medium'), 1.0), ('45', 'Medium'): (('90000', 'Male'), 1.0), ('Male', 'Medium'): (('45', '90000'), 1.0), ('90000',): (('45', 'Male', 'Medium'), 1.0), ('45', '90000'): (('Male', 'Medium'), 1.0), ('90000', 'Male'): (('45', 'Medium'), 1.0), ('90000', 'Medium'): (('45', 'Male'), 1.0), ('45', '90000', 'Male'): (('Medium',), 1.0), ('45', '90000', 'Medium'): (('Male',), 1.0), ('45', 'Male', 'Medium'): (('90000',), 1.0), ('90000', 'Male', 'Medium'): (('45',), 1.0), ('33',): (('65000', 'Low', 'Male'), 1.0), ('33', 'Low'): (('65000', 'Male'), 1.0), ('33', 'Male'): (('65000', 'Low'), 1.0), ('Low', 'Male'): (('33', '65000'), 1.0), ('65000',): (('33', 'Low', 'Male'), 1.0), ('33', '65000'): (('Low', 'Male'), 1.0), ('65000', 'Low'): (('33', 'Male'), 1.0), ('65000', 'Male'): (('33', 'Low'), 1.0), ('33', '65000', 'Low'): (('Male',), 1.0), ('33', '65000', 'Male'): (('Low',), 1.0), ('33', 'Low', 'Male'): (('65000',), 1.0), ('65000', 'Low', 'Male'): (('33',), 1.0), ('29',): (('59000', 'Female', 'Medium'), 1.0), ('29', 'Female'): (('59000', 'Medium'), 1.0), ('29', 'Medium'): (('59000', 'Female'), 1.0), ('59000',): (('29', 'Female', 'Medium'), 1.0), ('29', '59000'): (('Female', 'Medium'), 1.0), ('59000', 'Female'): (('29', 'Medium'), 1.0), ('59000', 'Medium'): (('29', 'Female'), 1.0), ('29', '59000', 'Female'): (('Medium',), 1.0), ('29', '59000', 'Medium'): (('Female',), 1.0), ('29', 'Female', 'Medium'): (('59000',), 1.0), ('59000', 'Female', 'Medium'): (('29',), 1.0)}\n"
     ]
    }
   ],
   "source": [
    "import pyfpgrowth\n",
    "\n",
    "# Convert numerical columns to strings within the transactions\n",
    "transactions = df[df['Anomaly']].drop(columns=['Anomaly']).astype(str).values.tolist()\n",
    "\n",
    "# Perform FP-Growth\n",
    "patterns = pyfpgrowth.find_frequent_patterns(transactions, 2)  # Adjust the support threshold as needed\n",
    "rules = pyfpgrowth.generate_association_rules(patterns, 0.7)  # Adjust the confidence threshold as needed\n",
    "\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e3da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1992f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cca0d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 30\n",
      "Filtered Data using Rule 1:\n",
      "Rule 2: Income >= 60000\n",
      "Filtered Data using Rule 2:\n",
      "Rule 3: Education == 'Low'\n",
      "Filtered Data using Rule 3:\n",
      "Rule 4: Gender == 'Female'\n",
      "Filtered Data using Rule 4:\n",
      "Rule 5: Age >= 30 & Income >= 60000\n",
      "Filtered Data using Rule 5:\n",
      "Rule 6: Age >= 30 & Education == 'Low'\n",
      "Filtered Data using Rule 6:\n",
      "Rule 7: Age >= 30 & Gender == 'Female'\n",
      "Filtered Data using Rule 7:\n",
      "Rule 8: Income >= 60000 & Education == 'Low'\n",
      "Filtered Data using Rule 8:\n",
      "Rule 9: Income >= 60000 & Gender == 'Female'\n",
      "Filtered Data using Rule 9:\n",
      "Rule 10: Education == 'Low' & Gender == 'Female'\n",
      "Filtered Data using Rule 10:\n",
      "Rule 11: Age >= 30 & Income >= 60000 & Education == 'Low'\n",
      "Filtered Data using Rule 11:\n",
      "Rule 12: Age >= 30 & Income >= 60000 & Gender == 'Female'\n",
      "Filtered Data using Rule 12:\n",
      "Rule 13: Age >= 30 & Education == 'Low' & Gender == 'Female'\n",
      "Filtered Data using Rule 13:\n",
      "Rule 14: Income >= 60000 & Education == 'Low' & Gender == 'Female'\n",
      "Filtered Data using Rule 14:\n",
      "Rule 15: Age >= 30 & Income >= 60000 & Education == 'Low' & Gender == 'Female'\n",
      "Filtered Data using Rule 15:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions\n",
    "rule_combinations = []\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        rule_combinations.append(combination)\n",
    "\n",
    "# Generate rules based on selected combinations\n",
    "rules = []\n",
    "for combination in rule_combinations:\n",
    "    conditions = []\n",
    "    for column in combination:\n",
    "        if df[column].dtype == 'object':\n",
    "            condition = f\"{column} == '{anomaly_df[column].iloc[0]}'\"\n",
    "        else:\n",
    "            condition = f\"{column} >= {anomaly_df[column].iloc[0]}\"\n",
    "        conditions.append(condition)\n",
    "    rule = \" & \".join(conditions)\n",
    "    rules.append(rule)\n",
    "\n",
    "# Apply the generated rules to the anomaly_df using the query method\n",
    "for i, rule in enumerate(rules, 1):\n",
    "    filtered_data = anomaly_df.query(rule)\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Filtered Data using Rule {i}:\")\n",
    "    #print(filtered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aae4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62843bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 33.333333333333336\n",
      "Filtered Data using Rule 1:\n",
      "Rule 2: Income >= 66500.0\n",
      "Filtered Data using Rule 2:\n",
      "Rule 3: Education == 'Low'\n",
      "Filtered Data using Rule 3:\n",
      "Rule 4: Gender == 'Female'\n",
      "Filtered Data using Rule 4:\n",
      "Rule 5: Age >= 33.333333333333336 & Income >= 66500.0\n",
      "Filtered Data using Rule 5:\n",
      "Rule 6: Age >= 33.333333333333336 & Education == 'Low'\n",
      "Filtered Data using Rule 6:\n",
      "Rule 7: Age >= 33.333333333333336 & Gender == 'Female'\n",
      "Filtered Data using Rule 7:\n",
      "Rule 8: Income >= 66500.0 & Education == 'Low'\n",
      "Filtered Data using Rule 8:\n",
      "Rule 9: Income >= 66500.0 & Gender == 'Female'\n",
      "Filtered Data using Rule 9:\n",
      "Rule 10: Education == 'Low' & Gender == 'Female'\n",
      "Filtered Data using Rule 10:\n",
      "Rule 11: Age >= 33.333333333333336 & Income >= 66500.0 & Education == 'Low'\n",
      "Filtered Data using Rule 11:\n",
      "Rule 12: Age >= 33.333333333333336 & Income >= 66500.0 & Gender == 'Female'\n",
      "Filtered Data using Rule 12:\n",
      "Rule 13: Age >= 33.333333333333336 & Education == 'Low' & Gender == 'Female'\n",
      "Filtered Data using Rule 13:\n",
      "Rule 14: Income >= 66500.0 & Education == 'Low' & Gender == 'Female'\n",
      "Filtered Data using Rule 14:\n",
      "Rule 15: Age >= 33.333333333333336 & Income >= 66500.0 & Education == 'Low' & Gender == 'Female'\n",
      "Filtered Data using Rule 15:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate means for numerical columns in 'anomaly_df'\n",
    "numerical_means = anomaly_df[['Age', 'Income']].mean()\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions\n",
    "rule_combinations = []\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        rule_combinations.append(combination)\n",
    "\n",
    "# Generate rules based on selected combinations\n",
    "rules = []\n",
    "for combination in rule_combinations:\n",
    "    conditions = []\n",
    "    for column in combination:\n",
    "        if df[column].dtype == 'object':\n",
    "            condition = f\"{column} == '{anomaly_df[column].iloc[0]}'\"\n",
    "        else:\n",
    "            # Use mean as cutoff for numerical columns\n",
    "            condition = f\"{column} >= {numerical_means[column]}\"\n",
    "        conditions.append(condition)\n",
    "    rule = \" & \".join(conditions)\n",
    "    rules.append(rule)\n",
    "\n",
    "# Apply the generated rules to the anomaly_df using the query method\n",
    "for i, rule in enumerate(rules, 1):\n",
    "    filtered_data = anomaly_df.query(rule)\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Filtered Data using Rule {i}:\")\n",
    "    #print(filtered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d753feaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54648b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 33.333333333333336\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 66500.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: Education == 'Low'\n",
      "Anomalies Count using Rule 3: 10\n",
      "\n",
      "Rule 4: Gender == 'Female'\n",
      "Anomalies Count using Rule 4: 15\n",
      "\n",
      "Rule 5: Age >= 33.333333333333336 & Income >= 66500.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 33.333333333333336 & Education == 'Low'\n",
      "Anomalies Count using Rule 6: 0\n",
      "\n",
      "Rule 7: Age >= 33.333333333333336 & Gender == 'Female'\n",
      "Anomalies Count using Rule 7: 5\n",
      "\n",
      "Rule 8: Income >= 66500.0 & Education == 'Low'\n",
      "Anomalies Count using Rule 8: 0\n",
      "\n",
      "Rule 9: Income >= 66500.0 & Gender == 'Female'\n",
      "Anomalies Count using Rule 9: 5\n",
      "\n",
      "Rule 10: Education == 'Low' & Gender == 'Female'\n",
      "Anomalies Count using Rule 10: 5\n",
      "\n",
      "Rule 11: Age >= 33.333333333333336 & Income >= 66500.0 & Education == 'Low'\n",
      "Anomalies Count using Rule 11: 0\n",
      "\n",
      "Rule 12: Age >= 33.333333333333336 & Income >= 66500.0 & Gender == 'Female'\n",
      "Anomalies Count using Rule 12: 5\n",
      "\n",
      "Rule 13: Age >= 33.333333333333336 & Education == 'Low' & Gender == 'Female'\n",
      "Anomalies Count using Rule 13: 0\n",
      "\n",
      "Rule 14: Income >= 66500.0 & Education == 'Low' & Gender == 'Female'\n",
      "Anomalies Count using Rule 14: 0\n",
      "\n",
      "Rule 15: Age >= 33.333333333333336 & Income >= 66500.0 & Education == 'Low' & Gender == 'Female'\n",
      "Anomalies Count using Rule 15: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate means for numerical columns in 'anomaly_df'\n",
    "numerical_means = anomaly_df[['Age', 'Income']].mean()\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions\n",
    "rule_combinations = []\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        rule_combinations.append(combination)\n",
    "\n",
    "# Generate rules based on selected combinations\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for combination in rule_combinations:\n",
    "    conditions = []\n",
    "    for column in combination:\n",
    "        if df[column].dtype == 'object':\n",
    "            condition = f\"{column} == '{anomaly_df[column].iloc[0]}'\"\n",
    "        else:\n",
    "            # Use mean as cutoff for numerical columns\n",
    "            condition = f\"{column} >= {numerical_means[column]}\"\n",
    "        conditions.append(condition)\n",
    "    rule = \" & \".join(conditions)\n",
    "    rules.append(rule)\n",
    "\n",
    "    # Count anomalies matching the rule\n",
    "    count = len(anomaly_df.query(rule))\n",
    "    anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b7fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60d9e63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentiles        Age   Income\n",
      "0.25  29.0  59000.0\n",
      "0.50  31.5  62500.0\n",
      "0.75  35.0  70000.0\n",
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: Education == 'Low'\n",
      "Anomalies Count using Rule 3: 10\n",
      "\n",
      "Rule 4: Gender == 'Female'\n",
      "Anomalies Count using Rule 4: 15\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & Education == 'Low'\n",
      "Anomalies Count using Rule 6: 0\n",
      "\n",
      "Rule 7: Age >= 35.0 & Gender == 'Female'\n",
      "Anomalies Count using Rule 7: 5\n",
      "\n",
      "Rule 8: Income >= 70000.0 & Education == 'Low'\n",
      "Anomalies Count using Rule 8: 0\n",
      "\n",
      "Rule 9: Income >= 70000.0 & Gender == 'Female'\n",
      "Anomalies Count using Rule 9: 5\n",
      "\n",
      "Rule 10: Education == 'Low' & Gender == 'Female'\n",
      "Anomalies Count using Rule 10: 5\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & Education == 'Low'\n",
      "Anomalies Count using Rule 11: 0\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & Gender == 'Female'\n",
      "Anomalies Count using Rule 12: 5\n",
      "\n",
      "Rule 13: Age >= 35.0 & Education == 'Low' & Gender == 'Female'\n",
      "Anomalies Count using Rule 13: 0\n",
      "\n",
      "Rule 14: Income >= 70000.0 & Education == 'Low' & Gender == 'Female'\n",
      "Anomalies Count using Rule 14: 0\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & Education == 'Low' & Gender == 'Female'\n",
      "Anomalies Count using Rule 15: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "print(\"percentiles\", percentiles)\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions\n",
    "rule_combinations = []\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        rule_combinations.append(combination)\n",
    "\n",
    "# Generate rules based on selected combinations\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for combination in rule_combinations:\n",
    "    conditions = []\n",
    "    for column in combination:\n",
    "        if df[column].dtype == 'object':\n",
    "            condition = f\"{column} == '{anomaly_df[column].iloc[0]}'\"\n",
    "        else:\n",
    "            # Use 75th percentile as cutoff for Age and Income\n",
    "            percentile_75 = percentiles.loc[0.75, column]\n",
    "            condition = f\"{column} >= {percentile_75}\"\n",
    "        conditions.append(condition)\n",
    "    rule = \" & \".join(conditions)\n",
    "    rules.append(rule)\n",
    "\n",
    "    # Count anomalies matching the rule\n",
    "    count = len(anomaly_df.query(rule))\n",
    "    anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a004b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1b252c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Rule  Anomaly_Count\n",
      "2                                  Education == 'Low'             30\n",
      "3                                  Gender == 'Female'             30\n",
      "9             Education == 'Low' & Gender == 'Female'             30\n",
      "0                           Age >= 33.333333333333336             10\n",
      "1                                   Income >= 66500.0             10\n",
      "4       Age >= 33.333333333333336 & Income >= 66500.0             10\n",
      "5      Age >= 33.333333333333336 & Education == 'Low'             10\n",
      "6      Age >= 33.333333333333336 & Gender == 'Female'             10\n",
      "7              Income >= 66500.0 & Education == 'Low'             10\n",
      "8              Income >= 66500.0 & Gender == 'Female'             10\n",
      "10  Age >= 33.333333333333336 & Income >= 66500.0 ...             10\n",
      "11  Age >= 33.333333333333336 & Income >= 66500.0 ...             10\n",
      "12  Age >= 33.333333333333336 & Education == 'Low'...             10\n",
      "13  Income >= 66500.0 & Education == 'Low' & Gende...             10\n",
      "14  Age >= 33.333333333333336 & Income >= 66500.0 ...             10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract rows where Anomaly is True\n",
    "anomaly_df = df[df['Anomaly'] == True]\n",
    "\n",
    "# Initialize an empty list to store the combinations and their anomaly counts\n",
    "rule_combinations = []\n",
    "anomaly_counts = []\n",
    "\n",
    "# Loop through the columns and generate combinations of rules\n",
    "for num_columns in range(1, len(anomaly_df.columns)):\n",
    "    for combination in itertools.combinations(anomaly_df.columns, num_columns):\n",
    "        # Exclude 'Anomaly' from the combination\n",
    "        if 'Anomaly' in combination:\n",
    "            continue\n",
    "        \n",
    "        # Create a rule for each value combination\n",
    "        rule = \"\"\n",
    "        subset = anomaly_df\n",
    "        \n",
    "        for column in combination:\n",
    "            if column in anomaly_df.select_dtypes(include='number').columns:\n",
    "                # For numeric columns, use >= as the condition\n",
    "                mean_value = anomaly_df[column].mean()\n",
    "                rule += f\"{column} >= {mean_value} & \"\n",
    "                subset = subset[subset[column] >= mean_value]\n",
    "            else:\n",
    "                # For categorical columns, include the category exactly as is\n",
    "                unique_value = anomaly_df[column].unique()[0]\n",
    "                rule += f\"{column} == '{unique_value}' & \"\n",
    "        \n",
    "        # Remove the trailing ' & ' from the rule\n",
    "        rule = rule[:-3]\n",
    "        \n",
    "        # Count the number of anomalies for this rule\n",
    "        anomaly_count = len(subset)\n",
    "        \n",
    "        rule_combinations.append(rule)\n",
    "        anomaly_counts.append(anomaly_count)\n",
    "\n",
    "# Create a DataFrame to store the rules and their corresponding anomaly counts\n",
    "rule_df = pd.DataFrame({'Rule': rule_combinations, 'Anomaly_Count': anomaly_counts})\n",
    "\n",
    "# Sort the DataFrame by Anomaly_Count in descending order\n",
    "sorted_rule_df = rule_df.sort_values(by='Anomaly_Count', ascending=False)\n",
    "\n",
    "# Print the top 20 rules with the highest number of anomalies\n",
    "top_20_rules = sorted_rule_df.head(50)\n",
    "print(top_20_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456784d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9a765de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 6: 10\n",
      "\n",
      "Rule 7: Age >= 35.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 7: 10\n",
      "\n",
      "Rule 8: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 8: 10\n",
      "\n",
      "Rule 9: Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 9: 10\n",
      "\n",
      "Rule 10: (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 11: 10\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 12: 10\n",
      "\n",
      "Rule 13: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 13: 10\n",
      "\n",
      "Rule 14: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 14: 10\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 15: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions\n",
    "rule_combinations = []\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        rule_combinations.append(combination)\n",
    "\n",
    "# Generate rules based on selected combinations with both \"AND\" and \"OR\" conditions for categorical variables\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for combination in rule_combinations:\n",
    "    conditions = []\n",
    "    or_conditions = []\n",
    "    \n",
    "    for column in combination:\n",
    "        if df[column].dtype == 'object':\n",
    "            # Create an \"OR\" condition for categorical variables\n",
    "            unique_values = anomaly_df[column].unique()\n",
    "            or_condition = \" | \".join([f\"{column} == '{value}'\" for value in unique_values])\n",
    "            or_conditions.append(f\"({or_condition})\")\n",
    "        else:\n",
    "            # Use 75th percentile as cutoff for Age and Income\n",
    "            percentile_75 = percentiles.loc[0.75, column]\n",
    "            conditions.append(f\"{column} >= {percentile_75}\")\n",
    "    \n",
    "    if or_conditions:\n",
    "        # Combine \"OR\" conditions with \"AND\" conditions\n",
    "        conditions.extend(or_conditions)\n",
    "    \n",
    "    rule = \" & \".join(conditions)\n",
    "    rules.append(rule)\n",
    "\n",
    "    # Count anomalies matching the rule\n",
    "    count = len(anomaly_df.query(rule))\n",
    "    anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d9c71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "870e4ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 6: 10\n",
      "\n",
      "Rule 7: Age >= 35.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 7: 10\n",
      "\n",
      "Rule 8: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 8: 10\n",
      "\n",
      "Rule 9: Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 9: 10\n",
      "\n",
      "Rule 10: (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 11: 10\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 12: 10\n",
      "\n",
      "Rule 13: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 13: 10\n",
      "\n",
      "Rule 14: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 14: 10\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 15: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions with \"|\" and \"&\" for categorical variables\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        \n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Create an \"OR\" condition for categorical variables\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                or_condition = \" | \".join([f\"{column} == '{value}'\" for value in unique_values])\n",
    "                conditions.append(f\"({or_condition})\")\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine all conditions with \"&\" for this combination\n",
    "        rule = \" & \".join(conditions)\n",
    "        rules.append(rule)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "        anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037e023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "609aca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 6: 10\n",
      "\n",
      "Rule 7: Age >= 35.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 7: 10\n",
      "\n",
      "Rule 8: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 8: 10\n",
      "\n",
      "Rule 9: Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 9: 10\n",
      "\n",
      "Rule 10: (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 11: 10\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 12: 10\n",
      "\n",
      "Rule 13: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 13: 10\n",
      "\n",
      "Rule 14: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 14: 10\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 15: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions with \"|\" and \"&\" for categorical variables\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        \n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Create a mix of \"|\" and \"&\" conditions for categorical variables\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                or_condition = \" | \".join([f\"{column} == '{value}'\" for value in unique_values])\n",
    "                and_condition = f\"({or_condition})\"\n",
    "                conditions.append(and_condition)\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine all conditions with \"&\" for this combination\n",
    "        rule = \" & \".join(conditions)\n",
    "        rules.append(rule)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "        anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed2b725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c65615b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 6: 10\n",
      "\n",
      "Rule 7: Age >= 35.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 7: 10\n",
      "\n",
      "Rule 8: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 8: 10\n",
      "\n",
      "Rule 9: Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 9: 10\n",
      "\n",
      "Rule 10: (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 11: 10\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 12: 10\n",
      "\n",
      "Rule 13: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 13: 10\n",
      "\n",
      "Rule 14: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 14: 10\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 15: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions with \"|\" and \"&\" for categorical variables\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        \n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Create a mix of \"|\" and \"&\" conditions for categorical variables in the rule\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                or_condition = \" | \".join([f\"{column} == '{value}'\" for value in unique_values])\n",
    "                conditions.append(f\"({or_condition})\")\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine all conditions with \"&\" in the rule\n",
    "        rule = \" & \".join(conditions)\n",
    "        rules.append(rule)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "        anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f72e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f3e318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 6: 10\n",
      "\n",
      "Rule 7: Age >= 35.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 7: 10\n",
      "\n",
      "Rule 8: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 8: 10\n",
      "\n",
      "Rule 9: Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 9: 10\n",
      "\n",
      "Rule 10: (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 11: 10\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 12: 10\n",
      "\n",
      "Rule 13: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 13: 10\n",
      "\n",
      "Rule 14: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 14: 10\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 15: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions with \"|\" between different categorical variables\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        \n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Create an \"OR\" condition for categorical variables within the same rule\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                or_condition = \" | \".join([f\"{column} == '{value}'\" for value in unique_values])\n",
    "                conditions.append(f\"({or_condition})\")\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine all conditions with \"&\" in the rule\n",
    "        rule = \" & \".join(conditions)\n",
    "        rules.append(rule)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "        anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4ad20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10366489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 6: 10\n",
      "\n",
      "Rule 7: Age >= 35.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 7: 10\n",
      "\n",
      "Rule 8: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 8: 10\n",
      "\n",
      "Rule 9: Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 9: 10\n",
      "\n",
      "Rule 10: (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 11: 10\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 12: 10\n",
      "\n",
      "Rule 13: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 13: 10\n",
      "\n",
      "Rule 14: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 14: 10\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 15: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions with \"|\" between different categorical variables\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        \n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Create an \"OR\" condition for categorical variables within the same rule\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                or_condition = \" | \".join([f\"{column} == '{value}'\" for value in unique_values])\n",
    "                conditions.append(f\"({or_condition})\")\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine all conditions with \"&\" in the rule\n",
    "        rule = \" & \".join(conditions)\n",
    "        rules.append(rule)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "        anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76547d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fca5a441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 6: 10\n",
      "\n",
      "Rule 7: Age >= 35.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 7: 10\n",
      "\n",
      "Rule 8: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 8: 10\n",
      "\n",
      "Rule 9: Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 9: 10\n",
      "\n",
      "Rule 10: (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 11: 10\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 12: 10\n",
      "\n",
      "Rule 13: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 13: 10\n",
      "\n",
      "Rule 14: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 14: 10\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 15: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions with \"|\" between different categorical variables\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        \n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Combine different categorical variables in the same \"|\" condition\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                or_condition = \" | \".join([f\"{column} == '{value}'\" for value in unique_values])\n",
    "                conditions.append(f\"({or_condition})\")\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine all conditions with \"&\" in the rule\n",
    "        rule = \" & \".join(conditions)\n",
    "        rules.append(rule)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "        anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21eb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfac3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 6: 10\n",
      "\n",
      "Rule 7: Age >= 35.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 7: 10\n",
      "\n",
      "Rule 8: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 8: 10\n",
      "\n",
      "Rule 9: Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 9: 10\n",
      "\n",
      "Rule 10: (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 11: 10\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 12: 10\n",
      "\n",
      "Rule 13: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 13: 10\n",
      "\n",
      "Rule 14: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 14: 10\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 15: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions with \"|\" between different categorical variables\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        \n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Combine different categorical variables in the same \"|\" condition\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                or_condition = \" | \".join([f\"{column} == '{value}'\" for value in unique_values])\n",
    "                conditions.append(f\"({or_condition})\")\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine all conditions with \"&\" in the rule\n",
    "        rule = \" & \".join(conditions)\n",
    "        rules.append(rule)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "        anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b418890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a1c2b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: Education == 'Low' | Education == 'Medium' | Education == 'High'\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & Education == 'Low' | Education == 'Medium' | Education == 'High'\n",
      "Anomalies Count using Rule 6: 20\n",
      "\n",
      "Rule 7: Age >= 35.0 & Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 7: 20\n",
      "\n",
      "Rule 8: Income >= 70000.0 & Education == 'Low' | Education == 'Medium' | Education == 'High'\n",
      "Anomalies Count using Rule 8: 20\n",
      "\n",
      "Rule 9: Income >= 70000.0 & Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 9: 20\n",
      "\n",
      "Rule 10: Education == 'Low' | Education == 'Medium' | Education == 'High' | Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & Education == 'Low' | Education == 'Medium' | Education == 'High'\n",
      "Anomalies Count using Rule 11: 20\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 12: 20\n",
      "\n",
      "Rule 13: Age >= 35.0 & Education == 'Low' | Education == 'Medium' | Education == 'High' | Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 13: 30\n",
      "\n",
      "Rule 14: Income >= 70000.0 & Education == 'Low' | Education == 'Medium' | Education == 'High' | Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 14: 30\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & Education == 'Low' | Education == 'Medium' | Education == 'High' | Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 15: 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        categorical_conditions = []\n",
    "        \n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Create individual categorical conditions for each variable\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                categorical_conditions.append(\" | \".join([f\"{column} == '{value}'\" for value in unique_values]))\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine categorical conditions with \"|\" within the same rule\n",
    "        if categorical_conditions:\n",
    "            conditions.append(\" | \".join(categorical_conditions))\n",
    "        \n",
    "        # Combine all conditions with \"&\" in the rule\n",
    "        rule = \" & \".join(conditions)\n",
    "        rules.append(rule)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "        anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549ce7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "489a8310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: Education == 'Low' | Education == 'Medium' | Education == 'High'\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & Education == 'Low' | Education == 'Medium' | Education == 'High'\n",
      "Anomalies Count using Rule 6: 20\n",
      "\n",
      "Rule 7: Age >= 35.0 & Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 7: 20\n",
      "\n",
      "Rule 8: Income >= 70000.0 & Education == 'Low' | Education == 'Medium' | Education == 'High'\n",
      "Anomalies Count using Rule 8: 20\n",
      "\n",
      "Rule 9: Income >= 70000.0 & Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 9: 20\n",
      "\n",
      "Rule 10: Education == 'Low' | Education == 'Medium' | Education == 'High' | Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & Education == 'Low' | Education == 'Medium' | Education == 'High'\n",
      "Anomalies Count using Rule 11: 20\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 12: 20\n",
      "\n",
      "Rule 13: Age >= 35.0 & Education == 'Low' | Education == 'Medium' | Education == 'High' | Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 13: 30\n",
      "\n",
      "Rule 14: Income >= 70000.0 & Education == 'Low' | Education == 'Medium' | Education == 'High' | Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 14: 30\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & Education == 'Low' | Education == 'Medium' | Education == 'High' | Gender == 'Female' | Gender == 'Male'\n",
      "Anomalies Count using Rule 15: 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        categorical_conditions = []\n",
    "        \n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Create individual categorical conditions for each variable\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                categorical_conditions.append(\" | \".join([f\"{column} == '{value}'\" for value in unique_values]))\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine categorical conditions with \"|\" within the same rule\n",
    "        if categorical_conditions:\n",
    "            conditions.append(\" | \".join(categorical_conditions))\n",
    "        \n",
    "        # Combine all conditions with \"&\" in the rule\n",
    "        rule = \" & \".join(conditions)\n",
    "        rules.append(rule)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "        anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024f529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9bccdbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Age >= 35.0\n",
      "Anomalies Count using Rule 1: 10\n",
      "\n",
      "Rule 2: Income >= 70000.0\n",
      "Anomalies Count using Rule 2: 10\n",
      "\n",
      "Rule 3: (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 3: 30\n",
      "\n",
      "Rule 4: (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 4: 30\n",
      "\n",
      "Rule 5: Age >= 35.0 & Income >= 70000.0\n",
      "Anomalies Count using Rule 5: 10\n",
      "\n",
      "Rule 6: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 6: 10\n",
      "\n",
      "Rule 7: Age >= 35.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 7: 10\n",
      "\n",
      "Rule 8: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 8: 10\n",
      "\n",
      "Rule 9: Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 9: 10\n",
      "\n",
      "Rule 10: (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 10: 30\n",
      "\n",
      "Rule 11: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Rule 11: 10\n",
      "\n",
      "Rule 12: Age >= 35.0 & Income >= 70000.0 & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 12: 10\n",
      "\n",
      "Rule 13: Age >= 35.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 13: 10\n",
      "\n",
      "Rule 14: Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 14: 10\n",
      "\n",
      "Rule 15: Age >= 35.0 & Income >= 70000.0 & (Education == 'Low' | Education == 'Medium' | Education == 'High') & (Gender == 'Female' | Gender == 'Male')\n",
      "Anomalies Count using Rule 15: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Generate all possible combinations of conditions\n",
    "rules = []\n",
    "anomalies_count = []\n",
    "\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        \n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Create individual categorical conditions for each variable\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                categorical_conditions = [\n",
    "                    f\"{column} == '{value}'\" for value in unique_values\n",
    "                ]\n",
    "                conditions.append(\"(\" + \" | \".join(categorical_conditions) + \")\")\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine all conditions with \"&\" in the rule\n",
    "        rule = \" & \".join(conditions)\n",
    "        rules.append(rule)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "        anomalies_count.append(count)\n",
    "\n",
    "# Display rules along with anomalies count\n",
    "for i, (rule, count) in enumerate(zip(rules, anomalies_count), 1):\n",
    "    print(f\"Rule {i}: {rule}\")\n",
    "    print(f\"Anomalies Count using Rule {i}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d09e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dacbb894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Rule: (Education == 'Low' | Education == 'Medium' | Education == 'High')\n",
      "Anomalies Count using Best Rule: 30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 40, 45, 27, 33, 29] * 5,\n",
    "    'Income': [50000, 60000, 45000, 70000, 55000, 80000, 90000, 52000, 65000, 59000] * 5,\n",
    "    'Education': ['High', 'Low', 'Medium', 'Medium', 'High', 'Low', 'Medium', 'High', 'Low', 'Medium'] * 5,\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'] * 5,\n",
    "    'Anomaly': [False, True, False, True, True, False, True, False, True, True] * 5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where 'Anomaly' is True\n",
    "anomaly_df = df[df['Anomaly']]\n",
    "\n",
    "# Calculate percentiles for numerical columns in 'anomaly_df'\n",
    "percentiles = anomaly_df[['Age', 'Income']].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "# Define the columns you want to consider for generating rules\n",
    "columns_to_consider = ['Age', 'Income', 'Education', 'Gender']\n",
    "\n",
    "# Initialize variables to track the combination with the most anomalies\n",
    "max_anomalies = 0\n",
    "best_combination = []\n",
    "\n",
    "# Generate all possible combinations of conditions\n",
    "for r in range(1, len(columns_to_consider) + 1):\n",
    "    for combination in itertools.combinations(columns_to_consider, r):\n",
    "        conditions = []\n",
    "        for column in combination:\n",
    "            if df[column].dtype == 'object':\n",
    "                # Create individual categorical conditions for each variable\n",
    "                unique_values = anomaly_df[column].unique()\n",
    "                categorical_conditions = [\n",
    "                    f\"{column} == '{value}'\" for value in unique_values\n",
    "                ]\n",
    "                conditions.append(\"(\" + \" | \".join(categorical_conditions) + \")\")\n",
    "            else:\n",
    "                # Use 75th percentile as cutoff for Age and Income\n",
    "                percentile_75 = percentiles.loc[0.75, column]\n",
    "                conditions.append(f\"{column} >= {percentile_75}\")\n",
    "        \n",
    "        # Combine all conditions with \"&\" in the rule\n",
    "        rule = \" & \".join(conditions)\n",
    "\n",
    "        # Count anomalies matching the rule\n",
    "        count = len(anomaly_df.query(rule))\n",
    "\n",
    "        # Check if this combination produces more anomalies\n",
    "        if count > max_anomalies:\n",
    "            max_anomalies = count\n",
    "            best_combination = combination\n",
    "\n",
    "# Generate the rule based on the best combination\n",
    "best_conditions = []\n",
    "for column in best_combination:\n",
    "    if df[column].dtype == 'object':\n",
    "        unique_values = anomaly_df[column].unique()\n",
    "        categorical_conditions = [f\"{column} == '{value}'\" for value in unique_values]\n",
    "        best_conditions.append(\"(\" + \" | \".join(categorical_conditions) + \")\")\n",
    "    else:\n",
    "        percentile_75 = percentiles.loc[0.75, column]\n",
    "        best_conditions.append(f\"{column} >= {percentile_75}\")\n",
    "\n",
    "best_rule = \" & \".join(best_conditions)\n",
    "\n",
    "# Display the best rule and the number of anomalies it captures\n",
    "print(f\"Best Rule: {best_rule}\")\n",
    "print(f\"Anomalies Count using Best Rule: {max_anomalies}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217f015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
