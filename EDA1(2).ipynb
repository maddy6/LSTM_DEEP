{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebcd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "\n",
    "def advanced_eda(data_path):\n",
    "    # Load the data using pandas\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Display basic information about the data\n",
    "    print(\"Data Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Generate the pandas profiling report\n",
    "    profile = pp.ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n",
    "\n",
    "    # Save the report as an HTML file\n",
    "    report_name = \"data_eda_report.html\"\n",
    "    profile.to_file(report_name)\n",
    "\n",
    "    # Display the report in the notebook (for Jupyter or Google Colab)\n",
    "    profile.to_widgets()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    advanced_eda(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df1677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4c45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "\n",
    "def advanced_eda(data_path):\n",
    "    # Load the data using pandas\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Display basic information about the data\n",
    "    print(\"Data Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Generate the pandas profiling report\n",
    "    profile = pp.ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n",
    "\n",
    "    # Save the report as an HTML file\n",
    "    report_name = \"data_eda_report.html\"\n",
    "    profile.to_file(report_name)\n",
    "\n",
    "    # Display the report in the notebook (for Jupyter or Google Colab)\n",
    "    profile.to_widgets()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    advanced_eda(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf056245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def advanced_eda(data_path):\n",
    "    # Load the data using pandas\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Display basic information about the data\n",
    "    print(\"Data Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Summary statistics for numerical columns\n",
    "    print(\"Summary Statistics:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    # Check for missing values\n",
    "    print(\"Missing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # Histograms of numerical columns\n",
    "    numerical_columns = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    for col in numerical_columns:\n",
    "        plt.figure()\n",
    "        sns.histplot(df[col], kde=True)\n",
    "        plt.title(f\"Histogram of {col}\")\n",
    "        plt.show()\n",
    "\n",
    "    # Bar plots for categorical columns\n",
    "    categorical_columns = df.select_dtypes(include=[\"object\"]).columns\n",
    "    for col in categorical_columns:\n",
    "        plt.figure()\n",
    "        sns.countplot(data=df, x=col)\n",
    "        plt.title(f\"Bar Plot of {col}\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    advanced_eda(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782cd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def correlation_heatmap(data):\n",
    "    correlation_matrix = data.corr()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title(\"Correlation Matrix Heatmap\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    df = pd.read_csv(data_path)\n",
    "    correlation_heatmap(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def box_plots(data):\n",
    "    numerical_columns = data.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    for col in numerical_columns:\n",
    "        plt.figure()\n",
    "        sns.boxplot(x=data[col])\n",
    "        plt.title(f\"Box Plot of {col}\")\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    df = pd.read_csv(data_path)\n",
    "    box_plots(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5991c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff796664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def pair_plots(data):\n",
    "    numerical_columns = data.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    sns.pairplot(data[numerical_columns])\n",
    "    plt.title(\"Pair Plots of Numerical Variables\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    df = pd.read_csv(data_path)\n",
    "    pair_plots(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ccb97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def categorical_plots(data):\n",
    "    categorical_columns = data.select_dtypes(include=[\"object\"]).columns\n",
    "    for col in categorical_columns:\n",
    "        plt.figure()\n",
    "        sns.countplot(data=data, x=col)\n",
    "        plt.title(f\"Count Plot of {col}\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    df = pd.read_csv(data_path)\n",
    "    categorical_plots(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c958c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def kde_plots(data):\n",
    "    numerical_columns = data.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    for col in numerical_columns:\n",
    "        plt.figure()\n",
    "        sns.kdeplot(data[col], fill=True)\n",
    "        plt.title(f\"KDE Plot of {col}\")\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    df = pd.read_csv(data_path)\n",
    "    kde_plots(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d3dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ddd08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def correlation_with_target(data, target_column):\n",
    "    correlation_with_target = data.corr()[target_column].sort_values(ascending=False)\n",
    "    return correlation_with_target\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    df = pd.read_csv(data_path)\n",
    "    target_column = \"target_column\"  # Replace with the actual name of your target column\n",
    "    corr_with_target = correlation_with_target(df, target_column)\n",
    "    print(corr_with_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542548d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def pair_plots_with_hue(data):\n",
    "    numerical_columns = data.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    categorical_column = \"target_column\"  # Replace with the actual name of the categorical column\n",
    "    sns.pairplot(data, hue=categorical_column, vars=numerical_columns)\n",
    "    plt.title(\"Pair Plots with Hue\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    df = pd.read_csv(data_path)\n",
    "    pair_plots_with_hue(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b7015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f324475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scatter_plots(data):\n",
    "    numerical_columns = data.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    for col1 in numerical_columns:\n",
    "        for col2 in numerical_columns:\n",
    "            if col1 != col2:\n",
    "                plt.figure()\n",
    "                plt.scatter(data[col1], data[col2])\n",
    "                plt.xlabel(col1)\n",
    "                plt.ylabel(col2)\n",
    "                plt.title(f\"Scatter Plot of {col1} vs {col2}\")\n",
    "                plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    df = pd.read_csv(data_path)\n",
    "    scatter_plots(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db5886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c23b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def correlation_matrix(data):\n",
    "    correlation_matrix = data.corr()\n",
    "    return correlation_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"path_to_your_data.csv\"  # Replace with the actual path to your data\n",
    "    df = pd.read_csv(data_path)\n",
    "    corr_matrix = correlation_matrix(df)\n",
    "    print(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805fdce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed6785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "data = {\n",
    "    \"ID\": [f\"ID_{i:04}\" for i in range(n_samples)],\n",
    "    \"Product type\": np.random.choice([\"Forward\", \"Futures\"], n_samples),\n",
    "    \"Category\": np.random.choice([\"A\", \"B\", \"C\", \"D\"], n_samples),\n",
    "    \"Maturity currency\": np.random.choice([\"USD\", \"EUR\", \"GBP\", \"JPY\"], n_samples),\n",
    "    \"Lendable currency\": np.random.choice([\"USD\", \"EUR\", \"GBP\", \"JPY\"], n_samples),\n",
    "    \"Forward currency\": np.random.choice([\"USD\", \"EUR\", \"GBP\", \"JPY\"], n_samples),\n",
    "    \"Market value\": np.random.normal(1000, 100, n_samples),\n",
    "    \"Lendable value\": np.random.normal(500, 50, n_samples),\n",
    "    \"FX target maturity USD Value\": np.random.normal(1500, 200, n_samples)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d8d0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Product type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Maturity currency</th>\n",
       "      <th>Lendable currency</th>\n",
       "      <th>Forward currency</th>\n",
       "      <th>Market value</th>\n",
       "      <th>Lendable value</th>\n",
       "      <th>FX target maturity USD Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_0000</td>\n",
       "      <td>Forward</td>\n",
       "      <td>B</td>\n",
       "      <td>GBP</td>\n",
       "      <td>JPY</td>\n",
       "      <td>JPY</td>\n",
       "      <td>1052.112243</td>\n",
       "      <td>473.551115</td>\n",
       "      <td>1509.861666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_0001</td>\n",
       "      <td>Futures</td>\n",
       "      <td>C</td>\n",
       "      <td>JPY</td>\n",
       "      <td>EUR</td>\n",
       "      <td>GBP</td>\n",
       "      <td>1064.521559</td>\n",
       "      <td>447.172118</td>\n",
       "      <td>1653.767935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_0002</td>\n",
       "      <td>Forward</td>\n",
       "      <td>A</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>GBP</td>\n",
       "      <td>1055.560447</td>\n",
       "      <td>561.154153</td>\n",
       "      <td>1378.354699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_0003</td>\n",
       "      <td>Forward</td>\n",
       "      <td>A</td>\n",
       "      <td>JPY</td>\n",
       "      <td>JPY</td>\n",
       "      <td>GBP</td>\n",
       "      <td>1008.958068</td>\n",
       "      <td>487.057280</td>\n",
       "      <td>1572.623126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_0004</td>\n",
       "      <td>Forward</td>\n",
       "      <td>A</td>\n",
       "      <td>JPY</td>\n",
       "      <td>USD</td>\n",
       "      <td>JPY</td>\n",
       "      <td>980.266158</td>\n",
       "      <td>517.625248</td>\n",
       "      <td>1562.221998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Product type Category Maturity currency Lendable currency  \\\n",
       "0  ID_0000      Forward        B               GBP               JPY   \n",
       "1  ID_0001      Futures        C               JPY               EUR   \n",
       "2  ID_0002      Forward        A               EUR               EUR   \n",
       "3  ID_0003      Forward        A               JPY               JPY   \n",
       "4  ID_0004      Forward        A               JPY               USD   \n",
       "\n",
       "  Forward currency  Market value  Lendable value  FX target maturity USD Value  \n",
       "0              JPY   1052.112243      473.551115                   1509.861666  \n",
       "1              GBP   1064.521559      447.172118                   1653.767935  \n",
       "2              GBP   1055.560447      561.154153                   1378.354699  \n",
       "3              GBP   1008.958068      487.057280                   1572.623126  \n",
       "4              JPY    980.266158      517.625248                   1562.221998  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea92c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91789d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Product type Category Maturity currency Lendable currency  \\\n",
      "9    ID_0009      Futures        D               USD               USD   \n",
      "20   ID_0020      Futures        C               GBP               EUR   \n",
      "55   ID_0055      Futures        A               GBP               USD   \n",
      "62   ID_0062      Forward        C               GBP               JPY   \n",
      "68   ID_0068      Futures        A               EUR               JPY   \n",
      "71   ID_0071      Futures        B               GBP               EUR   \n",
      "73   ID_0073      Futures        C               EUR               GBP   \n",
      "85   ID_0085      Forward        A               USD               USD   \n",
      "104  ID_0104      Futures        B               JPY               EUR   \n",
      "120  ID_0120      Futures        B               JPY               JPY   \n",
      "121  ID_0121      Forward        C               JPY               USD   \n",
      "183  ID_0183      Forward        D               EUR               JPY   \n",
      "190  ID_0190      Forward        C               EUR               EUR   \n",
      "216  ID_0216      Futures        B               EUR               GBP   \n",
      "224  ID_0224      Futures        A               JPY               EUR   \n",
      "230  ID_0230      Futures        C               EUR               EUR   \n",
      "232  ID_0232      Futures        A               EUR               GBP   \n",
      "236  ID_0236      Futures        A               GBP               USD   \n",
      "245  ID_0245      Futures        D               EUR               EUR   \n",
      "279  ID_0279      Futures        D               GBP               JPY   \n",
      "342  ID_0342      Forward        C               USD               JPY   \n",
      "343  ID_0343      Futures        A               USD               EUR   \n",
      "403  ID_0403      Forward        B               USD               JPY   \n",
      "443  ID_0443      Futures        C               JPY               JPY   \n",
      "492  ID_0492      Forward        C               JPY               EUR   \n",
      "499  ID_0499      Futures        C               JPY               JPY   \n",
      "519  ID_0519      Futures        A               USD               GBP   \n",
      "544  ID_0544      Forward        D               EUR               USD   \n",
      "559  ID_0559      Futures        C               EUR               EUR   \n",
      "561  ID_0561      Forward        D               JPY               JPY   \n",
      "579  ID_0579      Futures        C               EUR               USD   \n",
      "582  ID_0582      Futures        A               EUR               JPY   \n",
      "591  ID_0591      Futures        C               EUR               GBP   \n",
      "594  ID_0594      Futures        D               USD               USD   \n",
      "612  ID_0612      Futures        D               EUR               GBP   \n",
      "655  ID_0655      Forward        C               USD               EUR   \n",
      "673  ID_0673      Futures        A               GBP               EUR   \n",
      "677  ID_0677      Futures        C               EUR               EUR   \n",
      "754  ID_0754      Futures        A               JPY               JPY   \n",
      "755  ID_0755      Futures        D               GBP               GBP   \n",
      "763  ID_0763      Futures        C               USD               JPY   \n",
      "782  ID_0782      Futures        D               GBP               JPY   \n",
      "817  ID_0817      Forward        C               GBP               JPY   \n",
      "822  ID_0822      Futures        D               USD               JPY   \n",
      "839  ID_0839      Forward        A               GBP               EUR   \n",
      "908  ID_0908      Forward        B               JPY               GBP   \n",
      "922  ID_0922      Forward        D               USD               EUR   \n",
      "933  ID_0933      Forward        C               USD               JPY   \n",
      "934  ID_0934      Futures        C               USD               USD   \n",
      "985  ID_0985      Futures        B               EUR               JPY   \n",
      "\n",
      "    Forward currency  Market value  Lendable value  \\\n",
      "9                JPY    705.961137      496.568298   \n",
      "20               JPY    937.328278      536.624605   \n",
      "55               USD    799.613764      358.392220   \n",
      "62               JPY    698.048784      406.512915   \n",
      "68               JPY   1080.712260      375.583632   \n",
      "71               USD   1050.547016      450.885298   \n",
      "73               USD   1275.966004      522.343625   \n",
      "85               JPY    999.069968      483.187263   \n",
      "104              USD    756.118284      587.746654   \n",
      "120              JPY    855.614518      401.646515   \n",
      "121              GBP    770.381905      444.140677   \n",
      "183              GBP   1148.986344      523.502209   \n",
      "190              JPY   1002.088649      354.650589   \n",
      "216              EUR   1202.360622      548.765623   \n",
      "224              JPY    857.604285      440.160568   \n",
      "230              GBP   1202.430962      614.082592   \n",
      "232              JPY   1018.970617      423.247988   \n",
      "236              EUR    935.851309      481.384047   \n",
      "245              USD   1035.561335      541.509591   \n",
      "279              USD   1058.441298      643.420153   \n",
      "342              JPY   1199.566749      555.041070   \n",
      "343              GBP   1310.991856      553.068548   \n",
      "403              GBP   1153.372771      597.662957   \n",
      "443              JPY   1134.046105      373.387696   \n",
      "492              USD   1068.205207      353.527565   \n",
      "499              USD   1074.268242      594.864435   \n",
      "519              EUR   1171.937791      369.843146   \n",
      "544              USD   1294.909443      516.148725   \n",
      "559              EUR   1298.525900      375.336459   \n",
      "561              EUR    968.647031      581.458318   \n",
      "579              EUR    874.149509      572.550072   \n",
      "582              USD   1242.671649      568.824823   \n",
      "591              USD   1038.961418      625.577828   \n",
      "594              GBP    736.425226      532.027147   \n",
      "612              USD   1262.079309      436.496946   \n",
      "655              USD   1008.199556      485.792245   \n",
      "673              JPY   1107.154315      513.340920   \n",
      "677              GBP   1039.792705      522.890280   \n",
      "754              EUR   1062.550802      662.154648   \n",
      "755              EUR   1088.523148      615.395813   \n",
      "763              JPY   1000.369567      529.136879   \n",
      "782              JPY    747.043992      450.242576   \n",
      "817              EUR   1047.944152      495.696515   \n",
      "822              USD    951.279708      523.218493   \n",
      "839              GBP   1269.303366      419.986445   \n",
      "908              JPY    936.269225      430.488904   \n",
      "922              JPY    725.249516      496.796112   \n",
      "933              JPY   1392.623771      550.081591   \n",
      "934              JPY    791.588706      569.672726   \n",
      "985              GBP    700.886403      521.409312   \n",
      "\n",
      "     FX target maturity USD Value  Anomaly Score  Anomaly  \n",
      "9                     1279.546052      -0.606063     True  \n",
      "20                    2130.411347      -0.592983     True  \n",
      "55                    1639.233599      -0.634513     True  \n",
      "62                    1364.271388      -0.634840     True  \n",
      "68                    1672.444702      -0.588245     True  \n",
      "71                     932.184268      -0.576272     True  \n",
      "73                    1691.340637      -0.580178     True  \n",
      "85                    2062.930889      -0.564794     True  \n",
      "104                   1537.865661      -0.601047     True  \n",
      "120                   1835.734935      -0.605870     True  \n",
      "121                   1117.671890      -0.606063     True  \n",
      "183                    973.853973      -0.591736     True  \n",
      "190                   1517.222174      -0.579234     True  \n",
      "216                   1862.681540      -0.584348     True  \n",
      "224                   1969.815157      -0.590820     True  \n",
      "230                   1756.819159      -0.629977     True  \n",
      "232                   1022.614026      -0.575396     True  \n",
      "236                    898.473532      -0.569446     True  \n",
      "245                    929.074667      -0.562179     True  \n",
      "279                   1678.413520      -0.566785     True  \n",
      "342                   1238.526044      -0.552525     True  \n",
      "343                   1180.425573      -0.633101     True  \n",
      "403                   1919.587868      -0.629096     True  \n",
      "443                   1669.376421      -0.602573     True  \n",
      "492                   1753.530302      -0.610212     True  \n",
      "499                   1869.872428      -0.557258     True  \n",
      "519                   1557.160657      -0.602146     True  \n",
      "544                   1638.094537      -0.573115     True  \n",
      "559                   1714.866601      -0.687433     True  \n",
      "561                   1915.013008      -0.550858     True  \n",
      "579                   1889.039015      -0.547087     True  \n",
      "582                   1574.042378      -0.570602     True  \n",
      "591                   1306.768655      -0.568996     True  \n",
      "594                   1298.879725      -0.580514     True  \n",
      "612                   1350.128462      -0.598795     True  \n",
      "655                    932.498712      -0.559457     True  \n",
      "673                    917.148802      -0.587201     True  \n",
      "677                    933.534815      -0.561589     True  \n",
      "754                   1977.674399      -0.639980     True  \n",
      "755                   1736.851329      -0.552100     True  \n",
      "763                    865.914853      -0.571291     True  \n",
      "782                   1820.867822      -0.604907     True  \n",
      "817                    864.659237      -0.556600     True  \n",
      "822                   2051.043549      -0.578186     True  \n",
      "839                   1488.520927      -0.597767     True  \n",
      "908                   2115.372074      -0.619975     True  \n",
      "922                   1626.490843      -0.591816     True  \n",
      "933                   1498.031038      -0.618804     True  \n",
      "934                   1162.298962      -0.574995     True  \n",
      "985                   1233.077879      -0.613813     True  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def detect_anomalies(data, anomaly_fraction=0.05):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "    # Fit the Isolation Forest model\n",
    "    model = IsolationForest(contamination=anomaly_fraction, random_state=42)\n",
    "    predictions = model.fit_predict(data[numerical_columns])\n",
    "\n",
    "    # Add the predictions to the dataframe\n",
    "    data[\"Anomaly\"] = predictions == -1\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    detected_anomalies = detect_anomalies(df)\n",
    "    print(detected_anomalies[detected_anomalies[\"Anomaly\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc5bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf795c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Product type Category Maturity currency Lendable currency  \\\n",
      "6    ID_0006      Forward        D               JPY               EUR   \n",
      "9    ID_0009      Futures        D               USD               USD   \n",
      "19   ID_0019      Forward        A               JPY               GBP   \n",
      "20   ID_0020      Futures        C               GBP               EUR   \n",
      "27   ID_0027      Futures        C               JPY               USD   \n",
      "..       ...          ...      ...               ...               ...   \n",
      "933  ID_0933      Forward        C               USD               JPY   \n",
      "934  ID_0934      Futures        C               USD               USD   \n",
      "958  ID_0958      Futures        A               GBP               USD   \n",
      "981  ID_0981      Futures        D               JPY               USD   \n",
      "985  ID_0985      Futures        B               EUR               JPY   \n",
      "\n",
      "    Forward currency  Market value  Lendable value  \\\n",
      "6                JPY    980.509172      408.969835   \n",
      "9                JPY    705.961137      496.568298   \n",
      "19               JPY    862.038184      563.617675   \n",
      "20               JPY    937.328278      536.624605   \n",
      "27               USD   1043.192254      620.583834   \n",
      "..               ...           ...             ...   \n",
      "933              JPY   1392.623771      550.081591   \n",
      "934              JPY    791.588706      569.672726   \n",
      "958              USD    928.116761      592.775166   \n",
      "981              GBP    980.949689      380.484782   \n",
      "985              GBP    700.886403      521.409312   \n",
      "\n",
      "     FX target maturity USD Value  Anomaly Score  Anomaly  \n",
      "6                     1903.055022      -0.581690     True  \n",
      "9                     1279.546052      -0.606063     True  \n",
      "19                    1828.122913      -0.514119     True  \n",
      "20                    2130.411347      -0.592983     True  \n",
      "27                    1345.077006      -0.560808     True  \n",
      "..                            ...            ...      ...  \n",
      "933                   1498.031038      -0.618804     True  \n",
      "934                   1162.298962      -0.574995     True  \n",
      "958                   1832.746566      -0.547120     True  \n",
      "981                   1354.365620      -0.552525     True  \n",
      "985                   1233.077879      -0.613813     True  \n",
      "\n",
      "[100 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def detect_anomalies(data, anomaly_fraction=0.05):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "    # Fit the Isolation Forest model\n",
    "    model = IsolationForest(contamination=anomaly_fraction, random_state=42)\n",
    "    predictions = model.fit_predict(data[numerical_columns])\n",
    "\n",
    "    # Add the predictions to the dataframe\n",
    "    data[\"Anomaly\"] = predictions == -1\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    detected_anomalies = detect_anomalies(df, anomaly_fraction=0.1)  # Update anomaly_fraction here\n",
    "    print(detected_anomalies[detected_anomalies[\"Anomaly\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37e7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = detected_anomalies[detected_anomalies[\"Anomaly\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c7c4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Product type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Maturity currency</th>\n",
       "      <th>Lendable currency</th>\n",
       "      <th>Forward currency</th>\n",
       "      <th>Market value</th>\n",
       "      <th>Lendable value</th>\n",
       "      <th>FX target maturity USD Value</th>\n",
       "      <th>Anomaly Score</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID_0006</td>\n",
       "      <td>Forward</td>\n",
       "      <td>D</td>\n",
       "      <td>JPY</td>\n",
       "      <td>EUR</td>\n",
       "      <td>JPY</td>\n",
       "      <td>980.509172</td>\n",
       "      <td>408.969835</td>\n",
       "      <td>1903.055022</td>\n",
       "      <td>-0.581690</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID_0009</td>\n",
       "      <td>Futures</td>\n",
       "      <td>D</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>JPY</td>\n",
       "      <td>705.961137</td>\n",
       "      <td>496.568298</td>\n",
       "      <td>1279.546052</td>\n",
       "      <td>-0.606063</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ID_0019</td>\n",
       "      <td>Forward</td>\n",
       "      <td>A</td>\n",
       "      <td>JPY</td>\n",
       "      <td>GBP</td>\n",
       "      <td>JPY</td>\n",
       "      <td>862.038184</td>\n",
       "      <td>563.617675</td>\n",
       "      <td>1828.122913</td>\n",
       "      <td>-0.514119</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ID_0020</td>\n",
       "      <td>Futures</td>\n",
       "      <td>C</td>\n",
       "      <td>GBP</td>\n",
       "      <td>EUR</td>\n",
       "      <td>JPY</td>\n",
       "      <td>937.328278</td>\n",
       "      <td>536.624605</td>\n",
       "      <td>2130.411347</td>\n",
       "      <td>-0.592983</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ID_0027</td>\n",
       "      <td>Futures</td>\n",
       "      <td>C</td>\n",
       "      <td>JPY</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>1043.192254</td>\n",
       "      <td>620.583834</td>\n",
       "      <td>1345.077006</td>\n",
       "      <td>-0.560808</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Product type Category Maturity currency Lendable currency  \\\n",
       "6   ID_0006      Forward        D               JPY               EUR   \n",
       "9   ID_0009      Futures        D               USD               USD   \n",
       "19  ID_0019      Forward        A               JPY               GBP   \n",
       "20  ID_0020      Futures        C               GBP               EUR   \n",
       "27  ID_0027      Futures        C               JPY               USD   \n",
       "\n",
       "   Forward currency  Market value  Lendable value  \\\n",
       "6               JPY    980.509172      408.969835   \n",
       "9               JPY    705.961137      496.568298   \n",
       "19              JPY    862.038184      563.617675   \n",
       "20              JPY    937.328278      536.624605   \n",
       "27              USD   1043.192254      620.583834   \n",
       "\n",
       "    FX target maturity USD Value  Anomaly Score  Anomaly  \n",
       "6                    1903.055022      -0.581690     True  \n",
       "9                    1279.546052      -0.606063     True  \n",
       "19                   1828.122913      -0.514119     True  \n",
       "20                   2130.411347      -0.592983     True  \n",
       "27                   1345.077006      -0.560808     True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2569e869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    900\n",
       "True     100\n",
       "Name: Anomaly, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831dcec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a546f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Anomaly Fraction: 0.14\n",
      "          ID Product type Category Maturity currency Lendable currency  \\\n",
      "6    ID_0006      Forward        D               JPY               EUR   \n",
      "9    ID_0009      Futures        D               USD               USD   \n",
      "19   ID_0019      Forward        A               JPY               GBP   \n",
      "20   ID_0020      Futures        C               GBP               EUR   \n",
      "26   ID_0026      Futures        B               GBP               USD   \n",
      "..       ...          ...      ...               ...               ...   \n",
      "969  ID_0969      Forward        A               USD               EUR   \n",
      "981  ID_0981      Futures        D               JPY               USD   \n",
      "985  ID_0985      Futures        B               EUR               JPY   \n",
      "990  ID_0990      Futures        D               EUR               JPY   \n",
      "993  ID_0993      Futures        A               EUR               USD   \n",
      "\n",
      "    Forward currency  Market value  Lendable value  \\\n",
      "6                JPY    980.509172      408.969835   \n",
      "9                JPY    705.961137      496.568298   \n",
      "19               JPY    862.038184      563.617675   \n",
      "20               JPY    937.328278      536.624605   \n",
      "26               USD    935.851840      443.489814   \n",
      "..               ...           ...             ...   \n",
      "969              EUR    954.446047      576.401568   \n",
      "981              GBP    980.949689      380.484782   \n",
      "985              GBP    700.886403      521.409312   \n",
      "990              USD   1046.667098      609.204837   \n",
      "993              USD   1174.736320      469.430738   \n",
      "\n",
      "     FX target maturity USD Value  Anomaly Score  Anomaly  \n",
      "6                     1903.055022      -0.581690     True  \n",
      "9                     1279.546052      -0.606063     True  \n",
      "19                    1828.122913      -0.514119     True  \n",
      "20                    2130.411347      -0.592983     True  \n",
      "26                    1884.689159      -0.526154     True  \n",
      "..                            ...            ...      ...  \n",
      "969                   1061.749230      -0.529071     True  \n",
      "981                   1354.365620      -0.552525     True  \n",
      "985                   1233.077879      -0.613813     True  \n",
      "990                   1657.983944      -0.516714     True  \n",
      "993                   1222.140254      -0.524079     True  \n",
      "\n",
      "[140 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def custom_anomaly_score(estimator, X, y_true=None):\n",
    "    # Calculate anomaly scores using decision_function\n",
    "    anomaly_scores = estimator.decision_function(X)\n",
    "    return np.mean(anomaly_scores)\n",
    "\n",
    "def find_optimal_anomaly_fraction(data, param_grid, cv=5):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "    # Create an Isolation Forest model\n",
    "    model = IsolationForest(random_state=42)\n",
    "\n",
    "    # Define custom scoring function based on anomaly scores\n",
    "    anomaly_scorer = make_scorer(custom_anomaly_score, greater_is_better=False)\n",
    "\n",
    "    # Perform random search to find the optimal anomaly_fraction\n",
    "    search = RandomizedSearchCV(model, param_distributions=param_grid, cv=cv, scoring=anomaly_scorer, random_state=42)\n",
    "    search.fit(data[numerical_columns])\n",
    "\n",
    "    # Get the best parameter\n",
    "    optimal_anomaly_fraction = search.best_params_[\"contamination\"]\n",
    "\n",
    "    return optimal_anomaly_fraction\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df # Your dataset here\n",
    "\n",
    "    # Define the range of anomaly_fraction values to search\n",
    "    param_grid = {\"contamination\": np.linspace(0.01, 0.5, 50)}\n",
    "\n",
    "    # Find the optimal anomaly_fraction\n",
    "    optimal_anomaly_fraction = find_optimal_anomaly_fraction(data, param_grid)\n",
    "    print(\"Optimal Anomaly Fraction:\", optimal_anomaly_fraction)\n",
    "\n",
    "    # Detect anomalies using the optimal anomaly_fraction\n",
    "    detected_anomalies = detect_anomalies(data, anomaly_fraction=optimal_anomaly_fraction)\n",
    "    print(detected_anomalies[detected_anomalies[\"Anomaly\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8237ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Product type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Maturity currency</th>\n",
       "      <th>Lendable currency</th>\n",
       "      <th>Forward currency</th>\n",
       "      <th>Market value</th>\n",
       "      <th>Lendable value</th>\n",
       "      <th>FX target maturity USD Value</th>\n",
       "      <th>Anomaly Score</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID_0006</td>\n",
       "      <td>Forward</td>\n",
       "      <td>D</td>\n",
       "      <td>JPY</td>\n",
       "      <td>EUR</td>\n",
       "      <td>JPY</td>\n",
       "      <td>980.509172</td>\n",
       "      <td>408.969835</td>\n",
       "      <td>1903.055022</td>\n",
       "      <td>-0.581690</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID_0009</td>\n",
       "      <td>Futures</td>\n",
       "      <td>D</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>JPY</td>\n",
       "      <td>705.961137</td>\n",
       "      <td>496.568298</td>\n",
       "      <td>1279.546052</td>\n",
       "      <td>-0.606063</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ID_0019</td>\n",
       "      <td>Forward</td>\n",
       "      <td>A</td>\n",
       "      <td>JPY</td>\n",
       "      <td>GBP</td>\n",
       "      <td>JPY</td>\n",
       "      <td>862.038184</td>\n",
       "      <td>563.617675</td>\n",
       "      <td>1828.122913</td>\n",
       "      <td>-0.514119</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ID_0020</td>\n",
       "      <td>Futures</td>\n",
       "      <td>C</td>\n",
       "      <td>GBP</td>\n",
       "      <td>EUR</td>\n",
       "      <td>JPY</td>\n",
       "      <td>937.328278</td>\n",
       "      <td>536.624605</td>\n",
       "      <td>2130.411347</td>\n",
       "      <td>-0.592983</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ID_0026</td>\n",
       "      <td>Futures</td>\n",
       "      <td>B</td>\n",
       "      <td>GBP</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>935.851840</td>\n",
       "      <td>443.489814</td>\n",
       "      <td>1884.689159</td>\n",
       "      <td>-0.526154</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Product type Category Maturity currency Lendable currency  \\\n",
       "6   ID_0006      Forward        D               JPY               EUR   \n",
       "9   ID_0009      Futures        D               USD               USD   \n",
       "19  ID_0019      Forward        A               JPY               GBP   \n",
       "20  ID_0020      Futures        C               GBP               EUR   \n",
       "26  ID_0026      Futures        B               GBP               USD   \n",
       "\n",
       "   Forward currency  Market value  Lendable value  \\\n",
       "6               JPY    980.509172      408.969835   \n",
       "9               JPY    705.961137      496.568298   \n",
       "19              JPY    862.038184      563.617675   \n",
       "20              JPY    937.328278      536.624605   \n",
       "26              USD    935.851840      443.489814   \n",
       "\n",
       "    FX target maturity USD Value  Anomaly Score  Anomaly  \n",
       "6                    1903.055022      -0.581690     True  \n",
       "9                    1279.546052      -0.606063     True  \n",
       "19                   1828.122913      -0.514119     True  \n",
       "20                   2130.411347      -0.592983     True  \n",
       "26                   1884.689159      -0.526154     True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = detected_anomalies[detected_anomalies[\"Anomaly\"]]\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42ebb853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    140\n",
       "Name: Anomaly, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b764adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0066c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74daac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Product type Category Maturity currency Lendable currency  \\\n",
      "0    ID_0000      Forward        B               GBP               JPY   \n",
      "1    ID_0001      Futures        C               JPY               EUR   \n",
      "2    ID_0002      Forward        A               EUR               EUR   \n",
      "3    ID_0003      Forward        A               JPY               JPY   \n",
      "4    ID_0004      Forward        A               JPY               USD   \n",
      "..       ...          ...      ...               ...               ...   \n",
      "995  ID_0995      Forward        A               USD               JPY   \n",
      "996  ID_0996      Forward        B               GBP               JPY   \n",
      "997  ID_0997      Futures        A               USD               EUR   \n",
      "998  ID_0998      Futures        C               EUR               EUR   \n",
      "999  ID_0999      Forward        A               JPY               EUR   \n",
      "\n",
      "    Forward currency  Market value  Lendable value  \\\n",
      "0                JPY   1052.112243      473.551115   \n",
      "1                GBP   1064.521559      447.172118   \n",
      "2                GBP   1055.560447      561.154153   \n",
      "3                GBP   1008.958068      487.057280   \n",
      "4                JPY    980.266158      517.625248   \n",
      "..               ...           ...             ...   \n",
      "995              USD    976.344471      488.024904   \n",
      "996              EUR   1113.562015      555.841689   \n",
      "997              GBP    889.370649      509.320808   \n",
      "998              EUR    917.548584      463.418413   \n",
      "999              JPY    939.141028      594.522034   \n",
      "\n",
      "     FX target maturity USD Value  Anomaly Score  Anomaly  \n",
      "0                     1509.861666      -0.404965    False  \n",
      "1                     1653.767935      -0.435370    False  \n",
      "2                     1378.354699      -0.426154    False  \n",
      "3                     1572.623126      -0.387135    False  \n",
      "4                     1562.221998      -0.396109    False  \n",
      "..                            ...            ...      ...  \n",
      "995                   1712.017948      -0.411322    False  \n",
      "996                   1489.695414      -0.454756    False  \n",
      "997                   1600.618074      -0.407356    False  \n",
      "998                   1436.250337      -0.414203    False  \n",
      "999                   1294.037630      -0.525677    False  \n",
      "\n",
      "[1000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def custom_anomaly_score(estimator, X, y_true=None):\n",
    "    # Calculate anomaly scores using decision_function\n",
    "    anomaly_scores = estimator.decision_function(X)\n",
    "    return np.mean(anomaly_scores)\n",
    "\n",
    "def detect_anomalies(data, anomaly_fraction=0.05):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "    # Create an Isolation Forest model\n",
    "    model = IsolationForest(contamination=anomaly_fraction, random_state=42)\n",
    "\n",
    "    # Fit the model and predict anomalies\n",
    "    predictions = model.fit_predict(data[numerical_columns])\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = predictions == -1\n",
    "\n",
    "    return data\n",
    "\n",
    "def find_optimal_anomaly_fraction(data, param_grid, cv=5):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "    # Create an Isolation Forest model\n",
    "    model = IsolationForest(random_state=42)\n",
    "\n",
    "    # Define custom scoring function based on anomaly scores\n",
    "    anomaly_scorer = make_scorer(custom_anomaly_score, greater_is_better=False)\n",
    "\n",
    "    # Perform random search to find the optimal anomaly_fraction\n",
    "    search = RandomizedSearchCV(model, param_distributions=param_grid, cv=cv, scoring=anomaly_scorer, random_state=42)\n",
    "    search.fit(data[numerical_columns])\n",
    "\n",
    "    # Get the best parameter\n",
    "    optimal_anomaly_fraction = search.best_params_[\"contamination\"]\n",
    "\n",
    "    return optimal_anomaly_fraction\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df  # Your dataset here\n",
    "\n",
    "    # Define the range of anomaly_fraction values to search\n",
    "    param_grid = {\"contamination\": np.linspace(0.01, 0.5, 50)}\n",
    "\n",
    "    # Find the optimal anomaly_fraction\n",
    "    optimal_anomaly_fraction = find_optimal_anomaly_fraction(data, param_grid)\n",
    "\n",
    "    # Detect anomalies using the optimal anomaly_fraction and add the Anomaly column to the original dataset\n",
    "    detected_anomalies = detect_anomalies(data, anomaly_fraction=optimal_anomaly_fraction)\n",
    "\n",
    "    # Print the dataset with the Anomaly column\n",
    "    print(detected_anomalies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b0ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce6b6df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Product type Category Maturity currency Lendable currency  \\\n",
      "0    ID_0000      Forward        B               GBP               JPY   \n",
      "1    ID_0001      Futures        C               JPY               EUR   \n",
      "2    ID_0002      Forward        A               EUR               EUR   \n",
      "3    ID_0003      Forward        A               JPY               JPY   \n",
      "4    ID_0004      Forward        A               JPY               USD   \n",
      "..       ...          ...      ...               ...               ...   \n",
      "995  ID_0995      Forward        A               USD               JPY   \n",
      "996  ID_0996      Forward        B               GBP               JPY   \n",
      "997  ID_0997      Futures        A               USD               EUR   \n",
      "998  ID_0998      Futures        C               EUR               EUR   \n",
      "999  ID_0999      Forward        A               JPY               EUR   \n",
      "\n",
      "    Forward currency  Market value  Lendable value  \\\n",
      "0                JPY   1052.112243      473.551115   \n",
      "1                GBP   1064.521559      447.172118   \n",
      "2                GBP   1055.560447      561.154153   \n",
      "3                GBP   1008.958068      487.057280   \n",
      "4                JPY    980.266158      517.625248   \n",
      "..               ...           ...             ...   \n",
      "995              USD    976.344471      488.024904   \n",
      "996              EUR   1113.562015      555.841689   \n",
      "997              GBP    889.370649      509.320808   \n",
      "998              EUR    917.548584      463.418413   \n",
      "999              JPY    939.141028      594.522034   \n",
      "\n",
      "     FX target maturity USD Value  Anomaly Score  Anomaly  \n",
      "0                     1509.861666      -0.404965    False  \n",
      "1                     1653.767935      -0.435370    False  \n",
      "2                     1378.354699      -0.426154    False  \n",
      "3                     1572.623126      -0.387135    False  \n",
      "4                     1562.221998      -0.396109    False  \n",
      "..                            ...            ...      ...  \n",
      "995                   1712.017948      -0.411322    False  \n",
      "996                   1489.695414      -0.454756    False  \n",
      "997                   1600.618074      -0.407356    False  \n",
      "998                   1436.250337      -0.414203    False  \n",
      "999                   1294.037630      -0.525677    False  \n",
      "\n",
      "[1000 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def custom_anomaly_score(estimator, X, y_true=None):\n",
    "    # Calculate anomaly scores using decision_function\n",
    "    anomaly_scores = estimator.decision_function(X)\n",
    "    return np.mean(anomaly_scores)\n",
    "\n",
    "def detect_anomalies(data, anomaly_fraction=0.05):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "    # Create an Isolation Forest model\n",
    "    model = IsolationForest(contamination=anomaly_fraction, random_state=42)\n",
    "\n",
    "    # Fit the model and predict anomalies\n",
    "    predictions = model.fit_predict(data[numerical_columns])\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = predictions == -1\n",
    "\n",
    "    return data\n",
    "\n",
    "def find_optimal_anomaly_fraction(data, param_grid, cv=5):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "    # Create an Isolation Forest model\n",
    "    model = IsolationForest(random_state=42)\n",
    "\n",
    "    # Define custom scoring function based on anomaly scores\n",
    "    anomaly_scorer = make_scorer(custom_anomaly_score, greater_is_better=False)\n",
    "\n",
    "    # Perform random search to find the optimal anomaly_fraction\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        search = RandomizedSearchCV(model, param_distributions=param_grid, cv=cv, scoring=anomaly_scorer, random_state=42)\n",
    "        search.fit(data[numerical_columns])\n",
    "\n",
    "    # Get the best parameter\n",
    "    optimal_anomaly_fraction = search.best_params_[\"contamination\"]\n",
    "\n",
    "    return optimal_anomaly_fraction\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df  # Your dataset here\n",
    "\n",
    "    # Define the range of anomaly_fraction values to search\n",
    "    param_grid = {\"contamination\": np.linspace(0.01, 0.5, 50)}\n",
    "\n",
    "    # Find the optimal anomaly_fraction\n",
    "    optimal_anomaly_fraction = find_optimal_anomaly_fraction(data, param_grid)\n",
    "\n",
    "    # Detect anomalies using the optimal anomaly_fraction and add the Anomaly column to the original dataset\n",
    "    detected_anomalies = detect_anomalies(data, anomaly_fraction=optimal_anomaly_fraction)\n",
    "\n",
    "    # Print the dataset with the Anomaly column\n",
    "    print(detected_anomalies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e6ccea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Product type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Maturity currency</th>\n",
       "      <th>Lendable currency</th>\n",
       "      <th>Forward currency</th>\n",
       "      <th>Market value</th>\n",
       "      <th>Lendable value</th>\n",
       "      <th>FX target maturity USD Value</th>\n",
       "      <th>Anomaly Score</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_0000</td>\n",
       "      <td>Forward</td>\n",
       "      <td>B</td>\n",
       "      <td>GBP</td>\n",
       "      <td>JPY</td>\n",
       "      <td>JPY</td>\n",
       "      <td>1052.112243</td>\n",
       "      <td>473.551115</td>\n",
       "      <td>1509.861666</td>\n",
       "      <td>-0.404965</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_0001</td>\n",
       "      <td>Futures</td>\n",
       "      <td>C</td>\n",
       "      <td>JPY</td>\n",
       "      <td>EUR</td>\n",
       "      <td>GBP</td>\n",
       "      <td>1064.521559</td>\n",
       "      <td>447.172118</td>\n",
       "      <td>1653.767935</td>\n",
       "      <td>-0.435370</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_0002</td>\n",
       "      <td>Forward</td>\n",
       "      <td>A</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>GBP</td>\n",
       "      <td>1055.560447</td>\n",
       "      <td>561.154153</td>\n",
       "      <td>1378.354699</td>\n",
       "      <td>-0.426154</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_0003</td>\n",
       "      <td>Forward</td>\n",
       "      <td>A</td>\n",
       "      <td>JPY</td>\n",
       "      <td>JPY</td>\n",
       "      <td>GBP</td>\n",
       "      <td>1008.958068</td>\n",
       "      <td>487.057280</td>\n",
       "      <td>1572.623126</td>\n",
       "      <td>-0.387135</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_0004</td>\n",
       "      <td>Forward</td>\n",
       "      <td>A</td>\n",
       "      <td>JPY</td>\n",
       "      <td>USD</td>\n",
       "      <td>JPY</td>\n",
       "      <td>980.266158</td>\n",
       "      <td>517.625248</td>\n",
       "      <td>1562.221998</td>\n",
       "      <td>-0.396109</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Product type Category Maturity currency Lendable currency  \\\n",
       "0  ID_0000      Forward        B               GBP               JPY   \n",
       "1  ID_0001      Futures        C               JPY               EUR   \n",
       "2  ID_0002      Forward        A               EUR               EUR   \n",
       "3  ID_0003      Forward        A               JPY               JPY   \n",
       "4  ID_0004      Forward        A               JPY               USD   \n",
       "\n",
       "  Forward currency  Market value  Lendable value  \\\n",
       "0              JPY   1052.112243      473.551115   \n",
       "1              GBP   1064.521559      447.172118   \n",
       "2              GBP   1055.560447      561.154153   \n",
       "3              GBP   1008.958068      487.057280   \n",
       "4              JPY    980.266158      517.625248   \n",
       "\n",
       "   FX target maturity USD Value  Anomaly Score  Anomaly  \n",
       "0                   1509.861666      -0.404965    False  \n",
       "1                   1653.767935      -0.435370    False  \n",
       "2                   1378.354699      -0.426154    False  \n",
       "3                   1572.623126      -0.387135    False  \n",
       "4                   1562.221998      -0.396109    False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_anomalies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3400579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    860\n",
       "True     140\n",
       "Name: Anomaly, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_anomalies['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebdf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b352240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c0f44ea",
   "metadata": {},
   "source": [
    "# Local Outlier Factor (LOF):\n",
    "LOF is a density-based algorithm that measures the local deviation of a data point with respect to its neighbors. It identifies outliers based on the idea that outliers have lower local density compared to their neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f20d2905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Product type Category Maturity currency Lendable currency  \\\n",
      "0    ID_0000      Forward        B               GBP               JPY   \n",
      "1    ID_0001      Futures        C               JPY               EUR   \n",
      "2    ID_0002      Forward        A               EUR               EUR   \n",
      "3    ID_0003      Forward        A               JPY               JPY   \n",
      "4    ID_0004      Forward        A               JPY               USD   \n",
      "..       ...          ...      ...               ...               ...   \n",
      "995  ID_0995      Forward        A               USD               JPY   \n",
      "996  ID_0996      Forward        B               GBP               JPY   \n",
      "997  ID_0997      Futures        A               USD               EUR   \n",
      "998  ID_0998      Futures        C               EUR               EUR   \n",
      "999  ID_0999      Forward        A               JPY               EUR   \n",
      "\n",
      "    Forward currency  Market value  Lendable value  \\\n",
      "0                JPY   1052.112243      473.551115   \n",
      "1                GBP   1064.521559      447.172118   \n",
      "2                GBP   1055.560447      561.154153   \n",
      "3                GBP   1008.958068      487.057280   \n",
      "4                JPY    980.266158      517.625248   \n",
      "..               ...           ...             ...   \n",
      "995              USD    976.344471      488.024904   \n",
      "996              EUR   1113.562015      555.841689   \n",
      "997              GBP    889.370649      509.320808   \n",
      "998              EUR    917.548584      463.418413   \n",
      "999              JPY    939.141028      594.522034   \n",
      "\n",
      "     FX target maturity USD Value  Anomaly Score  Anomaly  \n",
      "0                     1509.861666      -0.404965    False  \n",
      "1                     1653.767935      -0.435370    False  \n",
      "2                     1378.354699      -0.426154    False  \n",
      "3                     1572.623126      -0.387135    False  \n",
      "4                     1562.221998      -0.396109    False  \n",
      "..                            ...            ...      ...  \n",
      "995                   1712.017948      -0.411322    False  \n",
      "996                   1489.695414      -0.454756    False  \n",
      "997                   1600.618074      -0.407356    False  \n",
      "998                   1436.250337      -0.414203    False  \n",
      "999                   1294.037630      -0.525677    False  \n",
      "\n",
      "[1000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "def detect_anomalies_lof(data, n_neighbors=20, contamination=0.05):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "    # Create the Local Outlier Factor model\n",
    "    model = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "\n",
    "    # Predict anomaly labels (-1 for anomalies, 1 for inliers)\n",
    "    predictions = model.fit_predict(data[numerical_columns])\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = predictions == -1\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df  # Your dataset here\n",
    "\n",
    "    # Detect anomalies using LOF and add the Anomaly column to the original dataset\n",
    "    detected_anomalies_lof = detect_anomalies_lof(data, n_neighbors=20, contamination=0.05)\n",
    "    print(detected_anomalies_lof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af70eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4fd1c2d",
   "metadata": {},
   "source": [
    "# One-Class SVM:\n",
    "One-Class SVM is a support vector machine algorithm that separates inliers from outliers in a high-dimensional space. It finds a hyperplane that captures the inliers' region and classifies points outside this region as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19ca0f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Product type Category Maturity currency Lendable currency  \\\n",
      "0    ID_0000      Forward        B               GBP               JPY   \n",
      "1    ID_0001      Futures        C               JPY               EUR   \n",
      "2    ID_0002      Forward        A               EUR               EUR   \n",
      "3    ID_0003      Forward        A               JPY               JPY   \n",
      "4    ID_0004      Forward        A               JPY               USD   \n",
      "..       ...          ...      ...               ...               ...   \n",
      "995  ID_0995      Forward        A               USD               JPY   \n",
      "996  ID_0996      Forward        B               GBP               JPY   \n",
      "997  ID_0997      Futures        A               USD               EUR   \n",
      "998  ID_0998      Futures        C               EUR               EUR   \n",
      "999  ID_0999      Forward        A               JPY               EUR   \n",
      "\n",
      "    Forward currency  Market value  Lendable value  \\\n",
      "0                JPY   1052.112243      473.551115   \n",
      "1                GBP   1064.521559      447.172118   \n",
      "2                GBP   1055.560447      561.154153   \n",
      "3                GBP   1008.958068      487.057280   \n",
      "4                JPY    980.266158      517.625248   \n",
      "..               ...           ...             ...   \n",
      "995              USD    976.344471      488.024904   \n",
      "996              EUR   1113.562015      555.841689   \n",
      "997              GBP    889.370649      509.320808   \n",
      "998              EUR    917.548584      463.418413   \n",
      "999              JPY    939.141028      594.522034   \n",
      "\n",
      "     FX target maturity USD Value  Anomaly Score  Anomaly  \n",
      "0                     1509.861666      -0.404965    False  \n",
      "1                     1653.767935      -0.435370    False  \n",
      "2                     1378.354699      -0.426154    False  \n",
      "3                     1572.623126      -0.387135    False  \n",
      "4                     1562.221998      -0.396109    False  \n",
      "..                            ...            ...      ...  \n",
      "995                   1712.017948      -0.411322    False  \n",
      "996                   1489.695414      -0.454756    False  \n",
      "997                   1600.618074      -0.407356    False  \n",
      "998                   1436.250337      -0.414203    False  \n",
      "999                   1294.037630      -0.525677    False  \n",
      "\n",
      "[1000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "def detect_anomalies_ocsvm(data, kernel='rbf', nu=0.05):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "    # Create the One-Class SVM model\n",
    "    model = OneClassSVM(kernel=kernel, nu=nu)\n",
    "\n",
    "    # Predict anomaly labels (-1 for anomalies, 1 for inliers)\n",
    "    predictions = model.fit_predict(data[numerical_columns])\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = predictions == -1\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df  # Your dataset here\n",
    "\n",
    "    # Detect anomalies using One-Class SVM and add the Anomaly column to the original dataset\n",
    "    detected_anomalies_ocsvm = detect_anomalies_ocsvm(data, kernel='rbf', nu=0.05)\n",
    "    print(detected_anomalies_ocsvm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01954a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33730fe9",
   "metadata": {},
   "source": [
    "# Autoencoders:\n",
    "Autoencoders are a type of neural network used for unsupervised learning. They are trained to reconstruct the input data and can be used for anomaly detection by comparing the reconstruction error.\n",
    "Here's a basic outline of using autoencoders for anomaly detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2ba5000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m data \u001b[38;5;241m=\u001b[39m df  \u001b[38;5;66;03m# Your dataset here\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Detect anomalies using Autoencoders and add the Anomaly column to the original dataset\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m detected_anomalies_autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_anomalies_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(detected_anomalies_autoencoder)\n",
      "Cell \u001b[1;32mIn[24], line 16\u001b[0m, in \u001b[0;36mdetect_anomalies_autoencoder\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Compile and fit the autoencoder\u001b[39;00m\n\u001b[0;32m     15\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate reconstruction errors\u001b[39;00m\n\u001b[0;32m     19\u001b[0m reconstructions \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mpredict(data[numerical_columns])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 963\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    966\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    786\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    789\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2523\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[38;5;66;03m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m placeholder_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_capture_func_lib  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[38;5;66;03m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2671\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2672\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2673\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2675\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2678\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1222\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:427\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    426\u001b[0m   program_ctx \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mProgramContext(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m--> 427\u001b[0m   converted_f \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_actual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_entity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogram_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mhas_verbosity(\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    429\u001b[0m     _log_callargs(converted_f, effective_args, kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:269\u001b[0m, in \u001b[0;36m_convert_actual\u001b[1;34m(entity, program_ctx)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(entity, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__code__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    265\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot apply autograph to a function that doesn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    266\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpose a __code__ object. If this is a @tf.function,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    267\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m try passing f.python_function instead.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 269\u001b[0m transformed, module, source_map \u001b[38;5;241m=\u001b[39m \u001b[43m_TRANSPILER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogram_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformed, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_module\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformed, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_source_map\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py:282\u001b[0m, in \u001b[0;36mGenericTranspiler.transform\u001b[1;34m(self, obj, user_context)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m\"\"\"Transforms a Python object.\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03mUsers typically call this method.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m  NotImplementedError: if the type of obj is not handled.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj):\n\u001b[1;32m--> 282\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon-function: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(obj)))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py:486\u001b[0m, in \u001b[0;36mPyToPy.transform_function\u001b[1;34m(self, fn, user_context)\u001b[0m\n\u001b[0;32m    482\u001b[0m         logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransformed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, fn, parser\u001b[38;5;241m.\u001b[39munparse(nodes))\n\u001b[0;32m    484\u001b[0m       factory \u001b[38;5;241m=\u001b[39m _PythonFnFactory(\n\u001b[0;32m    485\u001b[0m           ctx\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mname, fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m\u001b[38;5;241m.\u001b[39mco_freevars, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extra_locals())\n\u001b[1;32m--> 486\u001b[0m       \u001b[43mfactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m          \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[fn][cache_subkey] \u001b[38;5;241m=\u001b[39m factory\n\u001b[0;32m    490\u001b[0m transformed_fn \u001b[38;5;241m=\u001b[39m factory\u001b[38;5;241m.\u001b[39minstantiate(\n\u001b[0;32m    491\u001b[0m     globals_\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__globals__\u001b[39m,\n\u001b[0;32m    492\u001b[0m     closure\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__closure__\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (),\n\u001b[0;32m    493\u001b[0m     defaults\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__defaults__\u001b[39m,\n\u001b[0;32m    494\u001b[0m     kwdefaults\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__kwdefaults__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py:179\u001b[0m, in \u001b[0;36m_PythonFnFactory.create\u001b[1;34m(self, nodes, namer, inner_factory_name, outer_factory_name, future_features)\u001b[0m\n\u001b[0;32m    174\u001b[0m outer_factory_name \u001b[38;5;241m=\u001b[39m namer\u001b[38;5;241m.\u001b[39mnew_symbol(outer_factory_name, ())\n\u001b[0;32m    175\u001b[0m nodes \u001b[38;5;241m=\u001b[39m _wrap_into_factory(nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, inner_factory_name,\n\u001b[0;32m    176\u001b[0m                            outer_factory_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_freevars,\n\u001b[0;32m    177\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_locals\u001b[38;5;241m.\u001b[39mkeys(), future_features)\n\u001b[1;32m--> 179\u001b[0m module, _, source_map \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_ast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_source_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m outer_factory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, outer_factory_name)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbound_factory \u001b[38;5;241m=\u001b[39m outer_factory()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\loader.py:94\u001b[0m, in \u001b[0;36mload_ast\u001b[1;34m(nodes, indentation, include_source_map, delete_on_exit)\u001b[0m\n\u001b[0;32m     91\u001b[0m   nodes \u001b[38;5;241m=\u001b[39m (nodes,)\n\u001b[0;32m     93\u001b[0m source \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39munparse(nodes, indentation\u001b[38;5;241m=\u001b[39mindentation)\n\u001b[1;32m---> 94\u001b[0m module, _ \u001b[38;5;241m=\u001b[39m \u001b[43mload_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelete_on_exit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_source_map:\n\u001b[0;32m     97\u001b[0m   source_map \u001b[38;5;241m=\u001b[39m origin_info\u001b[38;5;241m.\u001b[39mcreate_source_map(nodes, source, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\loader.py:61\u001b[0m, in \u001b[0;36mload_source\u001b[1;34m(source, delete_on_exit)\u001b[0m\n\u001b[0;32m     59\u001b[0m spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mspec_from_file_location(module_name, file_name)\n\u001b[0;32m     60\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mmodule_from_spec(spec)\n\u001b[1;32m---> 61\u001b[0m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Use our own garbage-collected cache instead of sys.modules.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[module_name] \u001b[38;5;241m=\u001b[39m module\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1016\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "def detect_anomalies_autoencoder(data):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "    # Create the autoencoder model\n",
    "    input_layer = Input(shape=(len(numerical_columns),))\n",
    "    encoded = Dense(64, activation='relu')(input_layer)\n",
    "    decoded = Dense(len(numerical_columns), activation='linear')(encoded)\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "    # Compile and fit the autoencoder\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    autoencoder.fit(data[numerical_columns], data[numerical_columns], epochs=50, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Calculate reconstruction errors\n",
    "    reconstructions = autoencoder.predict(data[numerical_columns])\n",
    "    mse = np.mean(np.square(data[numerical_columns].values - reconstructions), axis=1)\n",
    "\n",
    "    # Set anomaly threshold\n",
    "    anomaly_threshold = np.percentile(mse, 95)\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = mse > anomaly_threshold\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df  # Your dataset here\n",
    "\n",
    "    # Detect anomalies using Autoencoders and add the Anomaly column to the original dataset\n",
    "    detected_anomalies_autoencoder = detect_anomalies_autoencoder(data)\n",
    "    print(detected_anomalies_autoencoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b23d9",
   "metadata": {},
   "source": [
    "# Sure! Below are the code examples for each of the mentioned advanced anomaly detection methods:\n",
    "\n",
    "Robust Random Cut Forest (RRCF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90350ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rrcf\n",
      "  Downloading rrcf-0.4.4.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\pixel\\anaconda3\\lib\\site-packages (from rrcf) (1.23.5)\n",
      "Building wheels for collected packages: rrcf\n",
      "  Building wheel for rrcf (setup.py): started\n",
      "  Building wheel for rrcf (setup.py): finished with status 'done'\n",
      "  Created wheel for rrcf: filename=rrcf-0.4.4-py3-none-any.whl size=10611 sha256=e850e374dc08c6640eaadbd65ae4fbb304d19c6f774e3ff99f3dcb9370e562e5\n",
      "  Stored in directory: c:\\users\\pixel\\appdata\\local\\pip\\cache\\wheels\\fa\\e6\\e7\\741e506e84a7739b37ed0b30e7e4e6812219231bb610fec416\n",
      "Successfully built rrcf\n",
      "Installing collected packages: rrcf\n",
      "Successfully installed rrcf-0.4.4\n"
     ]
    }
   ],
   "source": [
    "!pip install rrcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cbe2d74",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rrcf.isolation_forest'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrrcf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01misolation_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IsolationForest\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_anomalies_rrcf\u001b[39m(data, num_trees\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Select numerical columns for anomaly detection\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     numerical_columns \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rrcf.isolation_forest'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rrcf.isolation_forest import IsolationForest\n",
    "\n",
    "def detect_anomalies_rrcf(data, num_trees=100, sample_size=256, random_seed=42):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).values\n",
    "\n",
    "    # Create the Isolation Forest model\n",
    "    model = IsolationForest(n_trees=num_trees, sample_size=sample_size, random_seed=random_seed)\n",
    "\n",
    "    # Fit the model and predict anomaly labels\n",
    "    model.fit(numerical_columns)\n",
    "    predictions = model.predict(numerical_columns)\n",
    "\n",
    "    # Anomalies are considered data points with label -1 (anomaly)\n",
    "    anomalies = predictions == -1\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = anomalies\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df  # Your dataset here\n",
    "\n",
    "    # Detect anomalies using RRCF Isolation Forest and add the Anomaly column to the original dataset\n",
    "    detected_anomalies_rrcf = detect_anomalies_rrcf(data, num_trees=100, sample_size=256, random_seed=42)\n",
    "    print(detected_anomalies_rrcf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150f637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "573870b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Product type Category Maturity currency Lendable currency  \\\n",
      "0    ID_0000      Forward        B               GBP               JPY   \n",
      "1    ID_0001      Futures        C               JPY               EUR   \n",
      "2    ID_0002      Forward        A               EUR               EUR   \n",
      "3    ID_0003      Forward        A               JPY               JPY   \n",
      "4    ID_0004      Forward        A               JPY               USD   \n",
      "..       ...          ...      ...               ...               ...   \n",
      "995  ID_0995      Forward        A               USD               JPY   \n",
      "996  ID_0996      Forward        B               GBP               JPY   \n",
      "997  ID_0997      Futures        A               USD               EUR   \n",
      "998  ID_0998      Futures        C               EUR               EUR   \n",
      "999  ID_0999      Forward        A               JPY               EUR   \n",
      "\n",
      "    Forward currency  Market value  Lendable value  \\\n",
      "0                JPY   1052.112243      473.551115   \n",
      "1                GBP   1064.521559      447.172118   \n",
      "2                GBP   1055.560447      561.154153   \n",
      "3                GBP   1008.958068      487.057280   \n",
      "4                JPY    980.266158      517.625248   \n",
      "..               ...           ...             ...   \n",
      "995              USD    976.344471      488.024904   \n",
      "996              EUR   1113.562015      555.841689   \n",
      "997              GBP    889.370649      509.320808   \n",
      "998              EUR    917.548584      463.418413   \n",
      "999              JPY    939.141028      594.522034   \n",
      "\n",
      "     FX target maturity USD Value  Anomaly  \n",
      "0                     1509.861666     True  \n",
      "1                     1653.767935     True  \n",
      "2                     1378.354699     True  \n",
      "3                     1572.623126     True  \n",
      "4                     1562.221998     True  \n",
      "..                            ...      ...  \n",
      "995                   1712.017948     True  \n",
      "996                   1489.695414     True  \n",
      "997                   1600.618074     True  \n",
      "998                   1436.250337     True  \n",
      "999                   1294.037630     True  \n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def detect_anomalies_gmm(data, n_components=2, contamination=0.05):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).values\n",
    "\n",
    "    # Create the Gaussian Mixture Model\n",
    "    model = GaussianMixture(n_components=n_components, covariance_type='full', random_state=42)\n",
    "\n",
    "    # Fit the model and predict anomaly labels\n",
    "    model.fit(numerical_columns)\n",
    "    predictions = model.predict(numerical_columns)\n",
    "    probabilities = model.predict_proba(numerical_columns)\n",
    "\n",
    "    # Calculate the probability of each data point belonging to its assigned component\n",
    "    component_probabilities = probabilities[np.arange(len(predictions)), predictions]\n",
    "\n",
    "    # Set anomaly threshold based on the component with the lowest probability\n",
    "    anomaly_threshold = np.percentile(component_probabilities, 100 * (1 - contamination))\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = component_probabilities < anomaly_threshold\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df  # Your dataset here\n",
    "\n",
    "    # Detect anomalies using GMM and add the Anomaly column to the original dataset\n",
    "    detected_anomalies_gmm = detect_anomalies_gmm(data, n_components=2, contamination=0.05)\n",
    "    print(detected_anomalies_gmm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a542a1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     950\n",
       "False     50\n",
       "Name: Anomaly, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_anomalies_gmm['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85ef08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8831ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Product type Category Maturity currency Lendable currency  \\\n",
      "0    ID_0000      Forward        B               GBP               JPY   \n",
      "1    ID_0001      Futures        C               JPY               EUR   \n",
      "2    ID_0002      Forward        A               EUR               EUR   \n",
      "3    ID_0003      Forward        A               JPY               JPY   \n",
      "4    ID_0004      Forward        A               JPY               USD   \n",
      "..       ...          ...      ...               ...               ...   \n",
      "995  ID_0995      Forward        A               USD               JPY   \n",
      "996  ID_0996      Forward        B               GBP               JPY   \n",
      "997  ID_0997      Futures        A               USD               EUR   \n",
      "998  ID_0998      Futures        C               EUR               EUR   \n",
      "999  ID_0999      Forward        A               JPY               EUR   \n",
      "\n",
      "    Forward currency  Market value  Lendable value  \\\n",
      "0                JPY   1052.112243      473.551115   \n",
      "1                GBP   1064.521559      447.172118   \n",
      "2                GBP   1055.560447      561.154153   \n",
      "3                GBP   1008.958068      487.057280   \n",
      "4                JPY    980.266158      517.625248   \n",
      "..               ...           ...             ...   \n",
      "995              USD    976.344471      488.024904   \n",
      "996              EUR   1113.562015      555.841689   \n",
      "997              GBP    889.370649      509.320808   \n",
      "998              EUR    917.548584      463.418413   \n",
      "999              JPY    939.141028      594.522034   \n",
      "\n",
      "     FX target maturity USD Value  Anomaly  \n",
      "0                     1509.861666    False  \n",
      "1                     1653.767935    False  \n",
      "2                     1378.354699    False  \n",
      "3                     1572.623126    False  \n",
      "4                     1562.221998    False  \n",
      "..                            ...      ...  \n",
      "995                   1712.017948    False  \n",
      "996                   1489.695414    False  \n",
      "997                   1600.618074    False  \n",
      "998                   1436.250337    False  \n",
      "999                   1294.037630    False  \n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "def detect_anomalies_mahalanobis(data, contamination=0.05):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).values\n",
    "\n",
    "    # Compute the empirical covariance matrix\n",
    "    covariance_matrix = EmpiricalCovariance().fit(numerical_columns).covariance_\n",
    "\n",
    "    # Calculate Mahalanobis distance for each data point\n",
    "    mahalanobis_distances = np.sqrt(np.diag((numerical_columns - numerical_columns.mean(axis=0)).dot(np.linalg.pinv(covariance_matrix)).dot((numerical_columns - numerical_columns.mean(axis=0)).T)))\n",
    "\n",
    "    # Set anomaly threshold\n",
    "    anomaly_threshold = np.percentile(mahalanobis_distances, 100 * (1 - contamination))\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = mahalanobis_distances > anomaly_threshold\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df  # Your dataset here\n",
    "\n",
    "    # Detect anomalies using Mahalanobis distance and add the Anomaly column to the original dataset\n",
    "    detected_anomalies_mahalanobis = detect_anomalies_mahalanobis(data, contamination=0.05)\n",
    "    print(detected_anomalies_mahalanobis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88412355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    950\n",
       "True      50\n",
       "Name: Anomaly, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_anomalies_mahalanobis['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29963088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ca63017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Product type Category Maturity currency Lendable currency  \\\n",
      "0    ID_0000      Forward        B               GBP               JPY   \n",
      "1    ID_0001      Futures        C               JPY               EUR   \n",
      "2    ID_0002      Forward        A               EUR               EUR   \n",
      "3    ID_0003      Forward        A               JPY               JPY   \n",
      "4    ID_0004      Forward        A               JPY               USD   \n",
      "..       ...          ...      ...               ...               ...   \n",
      "995  ID_0995      Forward        A               USD               JPY   \n",
      "996  ID_0996      Forward        B               GBP               JPY   \n",
      "997  ID_0997      Futures        A               USD               EUR   \n",
      "998  ID_0998      Futures        C               EUR               EUR   \n",
      "999  ID_0999      Forward        A               JPY               EUR   \n",
      "\n",
      "    Forward currency  Market value  Lendable value  \\\n",
      "0                JPY   1052.112243      473.551115   \n",
      "1                GBP   1064.521559      447.172118   \n",
      "2                GBP   1055.560447      561.154153   \n",
      "3                GBP   1008.958068      487.057280   \n",
      "4                JPY    980.266158      517.625248   \n",
      "..               ...           ...             ...   \n",
      "995              USD    976.344471      488.024904   \n",
      "996              EUR   1113.562015      555.841689   \n",
      "997              GBP    889.370649      509.320808   \n",
      "998              EUR    917.548584      463.418413   \n",
      "999              JPY    939.141028      594.522034   \n",
      "\n",
      "     FX target maturity USD Value  Anomaly  \n",
      "0                     1509.861666     True  \n",
      "1                     1653.767935     True  \n",
      "2                     1378.354699     True  \n",
      "3                     1572.623126     True  \n",
      "4                     1562.221998     True  \n",
      "..                            ...      ...  \n",
      "995                   1712.017948     True  \n",
      "996                   1489.695414     True  \n",
      "997                   1600.618074     True  \n",
      "998                   1436.250337     True  \n",
      "999                   1294.037630     True  \n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def detect_anomalies_dbscan(data, eps=0.5, min_samples=5):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).values\n",
    "\n",
    "    # Create the DBSCAN model\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "\n",
    "    # Predict cluster labels (including outliers as -1)\n",
    "    cluster_labels = model.fit_predict(numerical_columns)\n",
    "\n",
    "    # Anomalies are considered data points with cluster label -1\n",
    "    anomalies = cluster_labels == -1\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = anomalies\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df # Your dataset here\n",
    "\n",
    "    # Detect anomalies using DBSCAN and add the Anomaly column to the original dataset\n",
    "    detected_anomalies_dbscan = detect_anomalies_dbscan(data, eps=0.5, min_samples=5)\n",
    "    print(detected_anomalies_dbscan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bd5cbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    1000\n",
       "Name: Anomaly, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_anomalies_dbscan['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f0ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9870c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68e0e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "\n",
    "data = {\n",
    "    \"ID\": [f\"ID_{i:04}\" for i in range(n_samples)],\n",
    "    \"Product type\": np.random.choice([\"Forward\", \"Futures\"], n_samples),\n",
    "    \"Category\": np.random.choice([\"A\", \"B\", \"C\", \"D\"], n_samples),\n",
    "    \"Maturity currency\": np.random.choice([\"USD\", \"EUR\", \"GBP\", \"JPY\"], n_samples),\n",
    "    \"Lendable currency\": np.random.choice([\"USD\", \"EUR\", \"GBP\", \"JPY\"], n_samples),\n",
    "    \"Forward currency\": np.random.choice([\"USD\", \"EUR\", \"GBP\", \"JPY\"], n_samples),\n",
    "    \"Market value\": np.random.normal(1000, 100, n_samples),\n",
    "    \"Lendable value\": np.random.normal(500, 50, n_samples),\n",
    "    \"FX target maturity USD Value\": np.random.normal(1500, 200, n_samples)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2b51d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 2s 4ms/step - loss: nan\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 1s 5ms/step - loss: nan\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 1s 5ms/step - loss: nan\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 1s 5ms/step - loss: nan\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: nan\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "           ID Product type Category Maturity currency Lendable currency  \\\n",
      "0     ID_0000      Forward        C               GBP               JPY   \n",
      "1     ID_0001      Futures        D               JPY               EUR   \n",
      "2     ID_0002      Forward        C               JPY               USD   \n",
      "3     ID_0003      Forward        D               EUR               JPY   \n",
      "4     ID_0004      Forward        D               USD               USD   \n",
      "...       ...          ...      ...               ...               ...   \n",
      "9995  ID_9995      Futures        A               EUR               EUR   \n",
      "9996  ID_9996      Forward        A               EUR               JPY   \n",
      "9997  ID_9997      Futures        A               EUR               GBP   \n",
      "9998  ID_9998      Futures        D               JPY               EUR   \n",
      "9999  ID_9999      Forward        C               GBP               JPY   \n",
      "\n",
      "     Forward currency  Market value  Lendable value  \\\n",
      "0                 EUR   1041.768141      426.441831   \n",
      "1                 EUR   1009.336519      533.870649   \n",
      "2                 JPY    934.057311      587.191613   \n",
      "3                 USD   1000.400126      526.468678   \n",
      "4                 USD    928.561344      586.235003   \n",
      "...               ...           ...             ...   \n",
      "9995              JPY    966.817995      476.165232   \n",
      "9996              JPY    750.924826      510.622235   \n",
      "9997              GBP   1046.561751      545.995268   \n",
      "9998              EUR   1213.312608      544.736680   \n",
      "9999              GBP    962.373859      478.110868   \n",
      "\n",
      "      FX target maturity USD Value  Anomaly  \n",
      "0                      1392.168180    False  \n",
      "1                      1201.969311    False  \n",
      "2                      1629.383985    False  \n",
      "3                      1422.043745    False  \n",
      "4                      1439.791041    False  \n",
      "...                            ...      ...  \n",
      "9995                   1647.009547    False  \n",
      "9996                   1552.497850    False  \n",
      "9997                   1082.200689    False  \n",
      "9998                   1591.063538    False  \n",
      "9999                   1415.560495    False  \n",
      "\n",
      "[10000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def vae_loss(x, x_decoded_mean, z_mean, z_log_var):\n",
    "    reconstruction_loss = K.mean(K.square(x - x_decoded_mean), axis=-1)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return reconstruction_loss + kl_loss\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], K.int_shape(z_mean)[1]), mean=0., stddev=1.0)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "def detect_anomalies_vae(data, encoding_dim=32, epochs=5, batch_size=32):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).values\n",
    "\n",
    "    # Create the Variational Autoencoder model\n",
    "    input_layer = Input(shape=(numerical_columns.shape[1],))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    z_mean = Dense(encoding_dim)(encoded)\n",
    "    z_log_var = Dense(encoding_dim)(encoded)\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "    decoded = Dense(numerical_columns.shape[1], activation='sigmoid')(z)\n",
    "\n",
    "    vae = Model(input_layer, decoded)\n",
    "    vae.add_loss(vae_loss(input_layer, decoded, z_mean, z_log_var))\n",
    "\n",
    "    # Compile the VAE model\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    # Fit the VAE model\n",
    "    vae.fit(numerical_columns, epochs=epochs, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Calculate reconstruction errors\n",
    "    reconstructions = vae.predict(numerical_columns)\n",
    "    mse = np.mean(np.square(numerical_columns - reconstructions), axis=1)\n",
    "\n",
    "    # Set anomaly threshold\n",
    "    anomaly_threshold = np.percentile(mse, 95)\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = mse > anomaly_threshold\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df  # Your dataset here\n",
    "\n",
    "    # Detect anomalies using VAE and add the Anomaly column to the original dataset\n",
    "    detected_anomalies_vae = detect_anomalies_vae(data, encoding_dim=32, epochs=50, batch_size=32)\n",
    "    print(detected_anomalies_vae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "667c2a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    10000\n",
       "Name: Anomaly, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_anomalies_vae['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453827a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d804154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID Product type Category Maturity currency Lendable currency  \\\n",
      "0     ID_0000      Forward        C               GBP               JPY   \n",
      "1     ID_0001      Futures        D               JPY               EUR   \n",
      "2     ID_0002      Forward        C               JPY               USD   \n",
      "3     ID_0003      Forward        D               EUR               JPY   \n",
      "4     ID_0004      Forward        D               USD               USD   \n",
      "...       ...          ...      ...               ...               ...   \n",
      "9995  ID_9995      Futures        A               EUR               EUR   \n",
      "9996  ID_9996      Forward        A               EUR               JPY   \n",
      "9997  ID_9997      Futures        A               EUR               GBP   \n",
      "9998  ID_9998      Futures        D               JPY               EUR   \n",
      "9999  ID_9999      Forward        C               GBP               JPY   \n",
      "\n",
      "     Forward currency  Market value  Lendable value  \\\n",
      "0                 EUR   1041.768141      426.441831   \n",
      "1                 EUR   1009.336519      533.870649   \n",
      "2                 JPY    934.057311      587.191613   \n",
      "3                 USD   1000.400126      526.468678   \n",
      "4                 USD    928.561344      586.235003   \n",
      "...               ...           ...             ...   \n",
      "9995              JPY    966.817995      476.165232   \n",
      "9996              JPY    750.924826      510.622235   \n",
      "9997              GBP   1046.561751      545.995268   \n",
      "9998              EUR   1213.312608      544.736680   \n",
      "9999              GBP    962.373859      478.110868   \n",
      "\n",
      "      FX target maturity USD Value  Anomaly  \n",
      "0                      1392.168180    False  \n",
      "1                      1201.969311    False  \n",
      "2                      1629.383985    False  \n",
      "3                      1422.043745    False  \n",
      "4                      1439.791041    False  \n",
      "...                            ...      ...  \n",
      "9995                   1647.009547    False  \n",
      "9996                   1552.497850    False  \n",
      "9997                   1082.200689    False  \n",
      "9998                   1591.063538    False  \n",
      "9999                   1415.560495    False  \n",
      "\n",
      "[10000 rows x 10 columns]\n",
      "           ID Product type Category Maturity currency Lendable currency  \\\n",
      "0     ID_0000      Forward        C               GBP               JPY   \n",
      "1     ID_0001      Futures        D               JPY               EUR   \n",
      "2     ID_0002      Forward        C               JPY               USD   \n",
      "3     ID_0003      Forward        D               EUR               JPY   \n",
      "4     ID_0004      Forward        D               USD               USD   \n",
      "...       ...          ...      ...               ...               ...   \n",
      "9995  ID_9995      Futures        A               EUR               EUR   \n",
      "9996  ID_9996      Forward        A               EUR               JPY   \n",
      "9997  ID_9997      Futures        A               EUR               GBP   \n",
      "9998  ID_9998      Futures        D               JPY               EUR   \n",
      "9999  ID_9999      Forward        C               GBP               JPY   \n",
      "\n",
      "     Forward currency  Market value  Lendable value  \\\n",
      "0                 EUR   1041.768141      426.441831   \n",
      "1                 EUR   1009.336519      533.870649   \n",
      "2                 JPY    934.057311      587.191613   \n",
      "3                 USD   1000.400126      526.468678   \n",
      "4                 USD    928.561344      586.235003   \n",
      "...               ...           ...             ...   \n",
      "9995              JPY    966.817995      476.165232   \n",
      "9996              JPY    750.924826      510.622235   \n",
      "9997              GBP   1046.561751      545.995268   \n",
      "9998              EUR   1213.312608      544.736680   \n",
      "9999              GBP    962.373859      478.110868   \n",
      "\n",
      "      FX target maturity USD Value  Anomaly  \n",
      "0                      1392.168180    False  \n",
      "1                      1201.969311    False  \n",
      "2                      1629.383985    False  \n",
      "3                      1422.043745    False  \n",
      "4                      1439.791041    False  \n",
      "...                            ...      ...  \n",
      "9995                   1647.009547    False  \n",
      "9996                   1552.497850    False  \n",
      "9997                   1082.200689    False  \n",
      "9998                   1591.063538    False  \n",
      "9999                   1415.560495    False  \n",
      "\n",
      "[10000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).values\n",
    "\n",
    "    # Standardize the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    numerical_columns = scaler.fit_transform(numerical_columns)\n",
    "\n",
    "    return numerical_columns\n",
    "\n",
    "def detect_anomalies_isolation_forest(data, contamination=0.05, random_state=42):\n",
    "    numerical_columns = preprocess_data(data)\n",
    "\n",
    "    # Create the Isolation Forest model\n",
    "    model = IsolationForest(contamination=contamination, random_state=random_state)\n",
    "\n",
    "    # Fit the model and predict anomaly labels\n",
    "    predictions = model.fit_predict(numerical_columns)\n",
    "\n",
    "    # Anomalies are considered data points with label -1 (anomaly)\n",
    "    anomalies = predictions == -1\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = anomalies\n",
    "\n",
    "    return data\n",
    "\n",
    "def detect_anomalies_one_class_svm(data, nu=0.05):\n",
    "    numerical_columns = preprocess_data(data)\n",
    "\n",
    "    # Create the One-Class SVM model\n",
    "    model = OneClassSVM(nu=nu)\n",
    "\n",
    "    # Fit the model and predict anomaly labels\n",
    "    predictions = model.fit_predict(numerical_columns)\n",
    "\n",
    "    # Anomalies are considered data points with label -1 (anomaly)\n",
    "    anomalies = predictions == -1\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = anomalies\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df  # Your dataset here\n",
    "\n",
    "    # Detect anomalies using Isolation Forest and add the Anomaly column to the original dataset\n",
    "    detected_anomalies_iforest = detect_anomalies_isolation_forest(data, contamination=0.05, random_state=42)\n",
    "    print(detected_anomalies_iforest)\n",
    "\n",
    "    # Detect anomalies using One-Class SVM and add the Anomaly column to the original dataset\n",
    "    detected_anomalies_ocsvm = detect_anomalies_one_class_svm(data, nu=0.05)\n",
    "    print(detected_anomalies_ocsvm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "282040da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9502\n",
       "True      498\n",
       "Name: Anomaly, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_anomalies_iforest['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b1dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4977e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Contamination: 0.1\n",
      "           ID Product type Category Maturity currency Lendable currency  \\\n",
      "0     ID_0000      Forward        C               GBP               JPY   \n",
      "1     ID_0001      Futures        D               JPY               EUR   \n",
      "2     ID_0002      Forward        C               JPY               USD   \n",
      "3     ID_0003      Forward        D               EUR               JPY   \n",
      "4     ID_0004      Forward        D               USD               USD   \n",
      "...       ...          ...      ...               ...               ...   \n",
      "9995  ID_9995      Futures        A               EUR               EUR   \n",
      "9996  ID_9996      Forward        A               EUR               JPY   \n",
      "9997  ID_9997      Futures        A               EUR               GBP   \n",
      "9998  ID_9998      Futures        D               JPY               EUR   \n",
      "9999  ID_9999      Forward        C               GBP               JPY   \n",
      "\n",
      "     Forward currency  Market value  Lendable value  \\\n",
      "0                 EUR   1041.768141      426.441831   \n",
      "1                 EUR   1009.336519      533.870649   \n",
      "2                 JPY    934.057311      587.191613   \n",
      "3                 USD   1000.400126      526.468678   \n",
      "4                 USD    928.561344      586.235003   \n",
      "...               ...           ...             ...   \n",
      "9995              JPY    966.817995      476.165232   \n",
      "9996              JPY    750.924826      510.622235   \n",
      "9997              GBP   1046.561751      545.995268   \n",
      "9998              EUR   1213.312608      544.736680   \n",
      "9999              GBP    962.373859      478.110868   \n",
      "\n",
      "      FX target maturity USD Value  Anomaly  \n",
      "0                      1392.168180    False  \n",
      "1                      1201.969311    False  \n",
      "2                      1629.383985    False  \n",
      "3                      1422.043745    False  \n",
      "4                      1439.791041    False  \n",
      "...                            ...      ...  \n",
      "9995                   1647.009547    False  \n",
      "9996                   1552.497850     True  \n",
      "9997                   1082.200689    False  \n",
      "9998                   1591.063538    False  \n",
      "9999                   1415.560495    False  \n",
      "\n",
      "[10000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def find_best_contamination(data, random_state=42):\n",
    "    # Select numerical columns for anomaly detection\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).values\n",
    "\n",
    "    # Standardize the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    numerical_columns = scaler.fit_transform(numerical_columns)\n",
    "\n",
    "    # Split the data into train and validation sets\n",
    "    X_train, X_val = train_test_split(numerical_columns, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Try a range of contamination values\n",
    "    contamination_values = np.linspace(0.01, 0.1, num=10)\n",
    "    best_contamination = None\n",
    "    best_f1_score = 0.0\n",
    "\n",
    "    for contamination in contamination_values:\n",
    "        # Create the Isolation Forest model\n",
    "        model = IsolationForest(contamination=contamination, random_state=random_state)\n",
    "\n",
    "        # Fit the model on the training set\n",
    "        model.fit(X_train)\n",
    "\n",
    "        # Predict anomalies on the validation set\n",
    "        predictions = model.predict(X_val)\n",
    "\n",
    "        # Anomalies are considered data points with label -1 (anomaly)\n",
    "        anomalies = predictions == -1\n",
    "\n",
    "        # Evaluate the performance using F1 score (you can use other metrics)\n",
    "        true_anomalies = np.sum(anomalies)\n",
    "        false_positives = np.sum(anomalies)\n",
    "        false_negatives = np.sum(~anomalies)\n",
    "        precision = true_anomalies / (true_anomalies + false_positives)\n",
    "        recall = true_anomalies / (true_anomalies + false_negatives)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        # Keep track of the best contamination value\n",
    "        if f1_score > best_f1_score:\n",
    "            best_f1_score = f1_score\n",
    "            best_contamination = contamination\n",
    "\n",
    "    return best_contamination\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation (replace this with your actual data loading)\n",
    "    data = df # Your dataset here\n",
    "\n",
    "    # Find the best contamination value dynamically\n",
    "    best_contamination = find_best_contamination(data, random_state=42)\n",
    "    print(\"Best Contamination:\", best_contamination)\n",
    "\n",
    "    # Use the best contamination value to detect anomalies using Isolation Forest\n",
    "    detected_anomalies_iforest = detect_anomalies_isolation_forest(data, contamination=best_contamination, random_state=42)\n",
    "    print(detected_anomalies_iforest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ceea044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9000\n",
       "True     1000\n",
       "Name: Anomaly, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_anomalies_iforest['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823ade9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76ffd56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def find_best_contamination_lof(data, random_state=42):\n",
    "    numerical_columns = data.select_dtypes(include=[\"float64\"]).values\n",
    "\n",
    "    # Standardize the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    numerical_columns = scaler.fit_transform(numerical_columns)\n",
    "\n",
    "    # Create the LOF model\n",
    "    model = LocalOutlierFactor(n_neighbors=20, novelty=True)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(numerical_columns)\n",
    "\n",
    "    # Predict the anomaly score (the lower, the more abnormal)\n",
    "    anomaly_scores = -model.decision_function(numerical_columns)\n",
    "\n",
    "    # Sort the anomaly scores in ascending order\n",
    "    sorted_scores = np.sort(anomaly_scores)\n",
    "\n",
    "    # Find the index corresponding to the desired percentage of anomalies (e.g., 5%)\n",
    "    desired_percentile_index = int(0.05 * len(sorted_scores))\n",
    "\n",
    "    # Get the contamination value corresponding to the desired percentile\n",
    "    best_contamination = sorted_scores[desired_percentile_index]\n",
    "\n",
    "    # Clip the best_contamination value to ensure it falls within the valid range (0, 0.5]\n",
    "    best_contamination = np.clip(best_contamination, 0.001, 0.5)\n",
    "\n",
    "    return best_contamination\n",
    "\n",
    "def detect_anomalies_lof(data):\n",
    "    # Find the best contamination value dynamically\n",
    "    best_contamination = find_best_contamination_lof(data, random_state=42)\n",
    "\n",
    "    numerical_columns = preprocess_data(data)\n",
    "\n",
    "    # Create the Local Outlier Factor model\n",
    "    model = LocalOutlierFactor(contamination=best_contamination)\n",
    "\n",
    "    # Fit the model and predict anomaly labels\n",
    "    predictions = model.fit_predict(numerical_columns)\n",
    "\n",
    "    # Anomalies are considered data points with label -1 (anomaly)\n",
    "    anomalies = predictions == -1\n",
    "\n",
    "    # Add the Anomaly column to the original dataframe\n",
    "    data[\"Anomaly\"] = anomalies\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fafc4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Product type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Maturity currency</th>\n",
       "      <th>Lendable currency</th>\n",
       "      <th>Forward currency</th>\n",
       "      <th>Market value</th>\n",
       "      <th>Lendable value</th>\n",
       "      <th>FX target maturity USD Value</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_0000</td>\n",
       "      <td>Forward</td>\n",
       "      <td>C</td>\n",
       "      <td>GBP</td>\n",
       "      <td>JPY</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1041.768141</td>\n",
       "      <td>426.441831</td>\n",
       "      <td>1392.168180</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_0001</td>\n",
       "      <td>Futures</td>\n",
       "      <td>D</td>\n",
       "      <td>JPY</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1009.336519</td>\n",
       "      <td>533.870649</td>\n",
       "      <td>1201.969311</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_0002</td>\n",
       "      <td>Forward</td>\n",
       "      <td>C</td>\n",
       "      <td>JPY</td>\n",
       "      <td>USD</td>\n",
       "      <td>JPY</td>\n",
       "      <td>934.057311</td>\n",
       "      <td>587.191613</td>\n",
       "      <td>1629.383985</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_0003</td>\n",
       "      <td>Forward</td>\n",
       "      <td>D</td>\n",
       "      <td>EUR</td>\n",
       "      <td>JPY</td>\n",
       "      <td>USD</td>\n",
       "      <td>1000.400126</td>\n",
       "      <td>526.468678</td>\n",
       "      <td>1422.043745</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_0004</td>\n",
       "      <td>Forward</td>\n",
       "      <td>D</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>928.561344</td>\n",
       "      <td>586.235003</td>\n",
       "      <td>1439.791041</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Product type Category Maturity currency Lendable currency  \\\n",
       "0  ID_0000      Forward        C               GBP               JPY   \n",
       "1  ID_0001      Futures        D               JPY               EUR   \n",
       "2  ID_0002      Forward        C               JPY               USD   \n",
       "3  ID_0003      Forward        D               EUR               JPY   \n",
       "4  ID_0004      Forward        D               USD               USD   \n",
       "\n",
       "  Forward currency  Market value  Lendable value  \\\n",
       "0              EUR   1041.768141      426.441831   \n",
       "1              EUR   1009.336519      533.870649   \n",
       "2              JPY    934.057311      587.191613   \n",
       "3              USD   1000.400126      526.468678   \n",
       "4              USD    928.561344      586.235003   \n",
       "\n",
       "   FX target maturity USD Value  Anomaly  \n",
       "0                   1392.168180    False  \n",
       "1                   1201.969311    False  \n",
       "2                   1629.383985    False  \n",
       "3                   1422.043745    False  \n",
       "4                   1439.791041    False  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = detect_anomalies_lof(df)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91e44f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9990\n",
       "True       10\n",
       "Name: Anomaly, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30085ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
